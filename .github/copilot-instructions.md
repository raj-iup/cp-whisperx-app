# Copilot Instructions â€” CP-WhisperX-App

**Version:** 6.2 (Syntax Error Prevention) | **Status:** ğŸŠ **100% PERFECT COMPLIANCE ACHIEVED** ğŸŠ | **Pre-commit Hook:** âœ… Active

**Major Updates in v6.2 (2025-12-03):**
- ğŸ› **Syntax Error Fixed**: Duplicate exc_info=True parameters (8 instances)
- ğŸ› **Error Handling Guide**: Added common mistake warning
- ğŸ“ **Best Practice**: Always use exc_info=True exactly once

**Major Updates in v6.1 (2025-12-03):**
- ğŸ› **Source Language Optional**: Transcribe workflow auto-detects language
- ğŸ› **TMDB Workflow-Aware**: Only enabled for subtitle workflow (movies/TV)
- ğŸ› **StageManifest Enhanced**: Added add_intermediate() method
- ğŸ› **Script Path Fixed**: Corrected TMDB script reference

**Major Updates in v6.0:**
- ğŸ†• **Automated Model Updates**: Weekly checks for new AI model releases
- ğŸ†• **Optimal Routing**: Data-driven model selection from AI_MODEL_ROUTING.md
- ğŸ†• **Cost Optimization**: Track and optimize AI usage costs
- ğŸ†• **Auto-Sync**: GitHub Actions keeps routing decisions current

---

## âš¡ Before You Respond

**Run this mental checklist:**
1. Will I use `logger` instead of `print()`? (Â§ 2.3)
2. Are imports organized Standard/Third-party/Local? (Â§ 6.1)
3. If stage: Does it use StageIO with `enable_manifest=True`? (Â§ 2.6)
4. Are outputs going to `io.stage_dir` only? (Â§ 1.1)
5. Am I using `load_config()` not `os.getenv()`? (Â§ 4.2)
6. **Is my code cross-platform? (Use `pathlib`, not hardcoded paths)** (Â§ 1.2)
7. **If creating shell script: Do I need Windows (.ps1) equivalent?** (Â§ 1.2)
8. **If creating stage script: Is it named `{NN}_{stage_name}.py`?** (File Naming)
9. **If testing: Am I using standard test media samples?** (Â§ 1.4) ğŸ†•
10. **If workflow: Am I following context-aware patterns?** (Â§ 1.5) ğŸ†•
11. **Error handling: Am I using exc_info=True exactly once?** (Â§ 5) ğŸ†•

**If NO to any â†’ Check the relevant Â§ section below**

---

## ğŸ“ Standard Test Media (ALWAYS USE THESE)

**Sample 1: English Technical**
- File: `in/Energy Demand in AI.mp4`
- Use for: Transcribe, Translate workflows
- Quality target: ASR WER â‰¤5%, Translation BLEU â‰¥90%

**Sample 2: Hinglish Bollywood**
- File: `in/test_clips/jaane_tu_test_clip.mp4`
- Use for: Subtitle, Transcribe, Translate workflows
- Quality target: ASR WER â‰¤15%, Subtitle Quality â‰¥88%

**See:** Â§ 1.4 for complete test media documentation

---

## ğŸ¯ Core Workflows (Context-Aware)

**1. Subtitle Workflow** (Â§ 1.5)
- Input: Bollywood/Indic media (movies/TV shows)
- Output: Multiple soft-embedded subtitle tracks (hi, en, gu, ta, es, ru, zh, ar)
- Features: Character names, cultural terms, speaker diarization, temporal coherence
- **TMDB:** âœ… Enabled (fetches cast, crew, character names)

**2. Transcribe Workflow** (Â§ 1.5)
- Input: Any media (YouTube, podcasts, lectures, general content)
- Output: Transcript in SAME language as source
- Features: Domain terminology, proper nouns, native script output
- **Source Language:** Optional (auto-detects if not specified)
- **TMDB:** âŒ Disabled (not needed for non-movie content)

**3. Translate Workflow** (Â§ 1.5)
- Input: Any media (YouTube, podcasts, lectures, general content)
- Output: Transcript in SPECIFIED target language
- Features: Cultural adaptation, glossary terms, formality preservation
- **Source Language:** Required (must be Indian language for IndicTrans2)
- **TMDB:** âŒ Disabled (not needed for non-movie content)

---

## ğŸ“ Model Routing (AUTO-UPDATED)

**Primary Source:** `docs/AI_MODEL_ROUTING.md` (auto-updates weekly)

**Quick Routing Principle:**
- Start with cheapest model that can do the task correctly
- Escalate only if: complexity increases, multi-file changes, high-risk territory, or stuck after 2 attempts

**Escalation Ladder:**
1. GPT-4 Turbo (default, small edits)
2. GPT-4o (fast iteration)  
3. Claude 3.5 Sonnet (refactoring, standards compliance)
4. o1 (deep reasoning, architecture)

**Task Types:**
- T1: Read/Explain â†’ GPT-4 Turbo
- T2: Small change (â‰¤1 file, â‰¤50 LOC) â†’ GPT-4o
- T3: Medium change (2-5 files) â†’ Claude 3.5 Sonnet
- T4: Large change (â‰¥6 files) â†’ o1 (high risk)
- T5: Debug/Investigate â†’ GPT-4 Turbo â†’ o1 (complex)
- T6: Docs/Comms â†’ GPT-4 Turbo
- T7: Standards compliance â†’ Claude 3.5 Sonnet

**Risk Levels:**
- Low: No stage boundaries, manifests, or CI
- Medium: Touches stage logic or multiple files
- High: Manifests, resume logic, CI, dependencies, >10 files

**Cost Monitoring:** Track usage with `./tools/model-usage-stats.py`

**See:** AI_MODEL_ROUTING.md Â§ 3 for complete routing table (updated weekly)

**Last Synced:** 2025-12-03 (auto-synced by GitHub Actions)

---

## Â§ 1.4 Standard Test Media (ALWAYS USE THESE)

**Purpose:** Establish reproducible testing baseline with diverse use cases.

### Sample 1: English Technical Content
**File:** `in/Energy Demand in AI.mp4`  
**Size:** ~14 MB | **Duration:** 2-5 minutes  
**Language:** English | **Type:** Technical/Educational  
**Use For:** Transcribe, Translate workflows

**Characteristics:**
- Clear English audio with technical terminology (AI, energy, demand)
- Minimal background noise
- Good for testing ASR accuracy on technical content
- Ideal for English-to-Indic translation testing

**Quality Targets:**
- ASR Accuracy: â‰¥95% WER
- Translation BLEU: â‰¥90%
- Processing Time: <3 minutes

### Sample 2: Hinglish Bollywood Content
**File:** `in/test_clips/jaane_tu_test_clip.mp4`  
**Size:** ~28 MB | **Duration:** 1-3 minutes  
**Language:** Hindi/Hinglish (mixed) | **Type:** Entertainment  
**Use For:** Subtitle, Transcribe, Translate workflows

**Characteristics:**
- Mixed Hindi-English (Hinglish) dialogue
- Bollywood dialogue patterns, emotional/casual speech
- Background music possible, multiple speakers
- Real-world subtitle generation challenge

**Quality Targets:**
- ASR Accuracy: â‰¥85% WER
- Subtitle Quality: â‰¥88%
- Context Awareness: â‰¥80%
- Glossary Application: 100%

**See:** `docs/user-guide/workflows.md` for detailed test scenarios

---

## Â§ 1.5 Core Workflows (Context-Aware)

### 1. Subtitle Workflow
**Purpose:** Generate context-aware multilingual subtitles for Bollywood/Indic media

**Input:** Indic/Hinglish movie media source  
**Output:** Original media + soft-embedded subtitle tracks (hi, en, gu, ta, es, ru, zh, ar)  
**Output Location:** `out/{date}/{user}/{job}/10_mux/{media_name}/`

**Pipeline:** demux â†’ tmdb âœ… â†’ glossary_load â†’ source_sep â†’ pyannote_vad â†’ whisperx_asr â†’ alignment â†’ translate â†’ subtitle_gen â†’ mux

**Context-Aware Features:**
- Character names preserved via glossary
- Cultural terms (Hindi idioms, relationship terms)
- Tone adaptation (formal vs. casual)
- Temporal coherence (consistent terminology)
- Speaker attribution (diarization)

**Example:**
```bash
./prepare-job.sh \
  --media in/test_clips/jaane_tu_test_clip.mp4 \
  --workflow subtitle \
  --source-language hi \
  --target-languages en,gu,ta,es,ru,zh,ar
```

### 2. Transcribe Workflow
**Purpose:** Create high-accuracy transcript in SOURCE language

**Input:** Any media source (YouTube, podcasts, lectures, general content)
**Output:** Text transcript in SAME language as source  
**Output Location:** `out/{date}/{user}/{job}/07_alignment/transcript.txt`

**Pipeline:** demux â†’ glossary_load â†’ source_sep (optional) â†’ pyannote_vad â†’ whisperx_asr â†’ alignment

**TMDB:** âŒ **Disabled** (not needed for non-movie content)

**Context-Aware Features:**
- Domain terminology preserved
- Proper nouns (names, places, organizations)
- Language-specific output (native script for Hindi)
- Context-aware punctuation
- Capitalization (proper noun detection for English)
- **Auto-detects language if not specified**

**Example:**
```bash
# Auto-detect language (NEW in v6.1)
./prepare-job.sh --media "in/Energy Demand in AI.mp4" --workflow transcribe

# Explicit English
./prepare-job.sh --media "in/Energy Demand in AI.mp4" --workflow transcribe -s en

# Hindi content
./prepare-job.sh --media in/test_clips/jaane_tu_test_clip.mp4 --workflow transcribe -s hi
```

### 3. Translate Workflow
**Purpose:** Create high-accuracy transcript in TARGET language

**Input:** Indian language media (IndicTrans2 constraint)
**Output:** Text transcript in SPECIFIED target language  
**Output Location:** `out/{date}/{user}/{job}/08_translate/transcript_{target_lang}.txt`

**Pipeline:** demux â†’ glossary_load â†’ source_sep (optional) â†’ pyannote_vad â†’ whisperx_asr â†’ alignment â†’ translate

**TMDB:** âŒ **Disabled** (not needed for non-movie content)

**Context-Aware Features:**
- Cultural adaptation (idioms, metaphors localized)
- Formality levels maintained
- Named entities transliterated appropriately
- Glossary terms preserved
- Temporal consistency (same term translated consistently)
- Numeric/date formats localized

**Translation Routing:**
- Indic languages: IndicTrans2 (highest quality)
- Non-Indic: NLLB-200 (broad support)
- Fallback: Hybrid approach

**Language Constraint (NEW in v6.1):**
- âœ… Source language **MUST** be Indian language (hi, ta, te, etc.)
- âœ… Target language can be ANY language
- âŒ Englishâ†’Hindi NOT supported (use transcribe instead)

**Example:**
```bash
# Hindi â†’ English (WORKS)
./prepare-job.sh --media in/test_clips/jaane_tu_test_clip.mp4 --workflow translate -s hi -t en

# Hindi â†’ Spanish (WORKS)
./prepare-job.sh --media in/test_clips/jaane_tu_test_clip.mp4 --workflow translate -s hi -t es

# English â†’ Hindi (FAILS - use transcribe instead)
# ./prepare-job.sh --media file.mp4 --workflow translate -s en -t hi  âŒ
```
# Hindi â†’ English
./prepare-job.sh --media in/test_clips/jaane_tu_test_clip.mp4 --workflow translate \
  --source-language hi --target-language en

# Hindi â†’ Spanish
./prepare-job.sh --media in/test_clips/jaane_tu_test_clip.mp4 --workflow translate \
  --source-language hi --target-language es
```

**See:** `docs/user-guide/workflows.md` for complete workflow documentation

---

## Â§ 1.6 Caching & ML Optimization

**Purpose:** Enable subsequent workflows with similar media to perform optimally over time.

### Intelligent Caching Layers

**1. Model Cache (Shared)**
- Location: `{cache_dir}/models/`
- Stores: Downloaded model weights (WhisperX, IndicTrans2, PyAnnote)
- Benefits: Avoid re-downloading 1-5 GB per run

**2. Audio Fingerprint Cache**
- Location: `{cache_dir}/fingerprints/`
- Stores: Audio characteristics, detected language, noise profile
- Benefits: Skip demux/analysis for identical media

**3. ASR Results Cache (Quality-Aware)**
- Location: `{cache_dir}/asr/`
- Cache Key: `SHA256(audio_content + model_version + language + config_params)`
- Benefits: Reuse ASR results for same audio (saves 2-10 minutes)
- Invalidation: Model version change, config parameter change, or `--no-cache` flag

**4. Translation Cache (Contextual)**
- Location: `{cache_dir}/translations/`
- Context-Aware Matching: Exact segment (100% reuse), similar segment >80% (reuse with adjustment)
- Benefits: Reuse translations for similar content (saves 1-5 minutes)

**5. Glossary Learning Cache**
- Location: `{cache_dir}/glossary_learned/`
- Stores: Per-movie learned terms, character names, cultural terms, frequency analysis
- Benefits: Improve accuracy on subsequent processing of same movie/genre

### ML-Based Optimization

**1. Adaptive Quality Prediction**
- ML Model: Lightweight XGBoost classifier
- Predicts: Optimal Whisper model size, source separation needed, expected ASR confidence
- Benefits: 30% faster processing on clean audio (use smaller model)

**2. Context Learning from History**
- Character name recognition from previous jobs
- Cultural term patterns learning
- Translation memory from approved translations
- Benefits: Consistent terminology, higher accuracy over time

**3. Similarity-Based Optimization**
- Detects similar media via audio fingerprinting
- Reuses processing decisions, glossaries, model selection
- Benefits: 40-95% time reduction on similar content

### Cache Configuration

**In config/.env.pipeline:**
```bash
# Caching Configuration
ENABLE_CACHING=true                          # Master switch
CACHE_DIR=~/.cp-whisperx/cache              # Cache location
CACHE_MAX_SIZE_GB=50                        # Total cache size limit
CACHE_ASR_RESULTS=true                      # Cache ASR outputs
CACHE_TRANSLATIONS=true                     # Cache translations
CACHE_AUDIO_FINGERPRINTS=true              # Cache audio analysis
CACHE_TTL_DAYS=90                          # Cache expiration (days)

# ML Optimization
ENABLE_ML_OPTIMIZATION=true                 # Enable ML predictions
ML_MODEL_SELECTION=adaptive                 # adaptive|fixed
ML_QUALITY_PREDICTION=true                  # Predict optimal settings
ML_LEARNING_FROM_HISTORY=true              # Learn from past jobs
```

### Cache Management

```bash
# View cache statistics
./tools/cache-manager.sh --stats

# Clear specific cache type
./tools/cache-manager.sh --clear asr

# Disable caching for one job
./prepare-job.sh --media in/file.mp4 --no-cache
```

### Expected Performance Improvements

| Scenario | First Run | Subsequent Run | Improvement |
|----------|-----------|----------------|-------------|
| Identical media | 10 min | 30 sec | 95% faster |
| Same movie, different cut | 10 min | 6 min | 40% faster |
| Similar Bollywood movie | 10 min | 8 min | 20% faster |

**See:** `docs/technical/caching-ml-optimization.md` for complete caching architecture

---

## ğŸš§ Implementation Status

**Current Architecture:** v2.0 (Simplified 3-6 Stage Pipeline)  
**Target Architecture:** v3.0 (Context-Aware Modular 10-Stage Pipeline)  
**Migration Progress:** 95% Documentation Complete (Phase 4)

### What Works Now (v2.0) âœ…

**Use These Patterns:**
- âœ… Configuration loading (100% compliant) - `load_config()`
- âœ… Logging system (100% compliant) - `logger.info()` not `print()`
- âœ… Multi-environment support - MLX/CUDA/CPU
- âœ… Error handling patterns - Try/except with logging
- âœ… Type hints and docstrings (100% compliant)
- âœ… Standard test media - Two samples defined (Â§ 1.4) ğŸ†•
- âœ… Core workflows documented - Subtitle/Transcribe/Translate (Â§ 1.5) ğŸ†•
- âœ… **StageManifest enhanced** - add_intermediate() method added (v6.1) ğŸ†•

**Partially Implemented:**
- âš ï¸ Stage module pattern (5% adoption) - Only `02_tmdb_enrichment.py`
- âš ï¸ Manifest tracking (10% adoption) - Few stages use it
- âš ï¸ Stage isolation (60% adoption) - Some shared state remains
- âš ï¸ Context-aware processing (40% adoption) - Basic implementation (Â§ 1.5) ğŸ†•
- âš ï¸ Intelligent caching (0% adoption) - Planned in Phase 5 (Â§ 1.6) ğŸ†•

### What's Coming (v3.0) â³

**In Active Development:**
- â³ Full 10-stage modular pipeline
- â³ Universal StageIO adoption (target: 100%)
- â³ Complete manifest tracking (target: 100%)
- â³ Stage-level testing infrastructure
- â³ Stage enable/disable per job
- â³ Advanced features (retry, caching, circuit breakers)

**See:** [Implementation Status Dashboard](../docs/IMPLEMENTATION_STATUS.md) for current progress.

### Code Generation Guidelines

**When generating NEW stage code:**
1. âœ… **Follow DEVELOPER_STANDARDS.md patterns** (even if not widely adopted yet)
2. âœ… **Use StageIO pattern with manifests** - This is the target state
3. âœ… **Write to io.stage_dir only** - Maintain stage isolation
4. âœ… **Use logger, not print** - Always use proper logging
5. âœ… **Add type hints and docstrings** - 100% compliance required
6. âœ… **Test with standard media samples** - Use samples from Â§ 1.4 ğŸ†•
7. âœ… **Implement caching support** - See Â§ 1.6 for patterns ğŸ†•

**When modifying EXISTING code:**
1. ğŸ¯ **Match existing patterns** for consistency
2. ğŸ“ **Add TODO comment** for v3.0 migration if applicable
3. ğŸ”„ **Consider gradual refactoring** if time permits
4. âš ï¸ **Note:** Existing stages may not follow StageIO pattern (migration in progress)

**Example for existing stage:**
```python
# TODO: v3.0 - Migrate to StageIO pattern with manifest tracking
# See: scripts/tmdb_enrichment_stage.py for reference implementation
```

---

## ğŸ—ºï¸ Quick Navigation Table

| Task | Section | Topics |
|------|---------|--------|
| Add new stage | Â§ 3.1 | StageIO, manifests, logging |
| Modify config | Â§ 4.2 | .env.pipeline, load_config() |
| Add logging | Â§ 2.3 | Logger usage, log levels |
| Error handling | Â§ 5 | Try/except, error logging |
| Manifest tracking | Â§ 2.5 | Input/output tracking |
| Organize imports | Â§ 6.1 | Standard/Third-party/Local |
| Type hints | Â§ 6.2 | Function signatures |
| Docstrings | Â§ 6.3 | Documentation |
| **Testing** | **Â§ 1.4** | **Standard test media** ğŸ†• |
| **Workflows** | **Â§ 1.5** | **Subtitle/Transcribe/Translate** ğŸ†• |
| **Caching** | **Â§ 1.6** | **ML optimization** ğŸ†• |

**Full standards:** `docs/developer/DEVELOPER_STANDARDS.md`

## ğŸ”’ Automated Enforcement

**Pre-commit Hook Active:**
- âœ… Validates all Python files before commit
- âœ… Blocks commits with violations
- âœ… Maintains 100% compliance automatically
- âœ… See: `docs/PRE_COMMIT_HOOK_GUIDE.md`

---

## ğŸŒ² Decision Trees

### Should I Create a New Stage?

```
Start here:
â”œâ”€ Is this a distinct transformation step? 
â”‚  â”œâ”€ NO â†’ Add to existing stage
â”‚  â””â”€ YES â†’ Continue
â”‚
â”œâ”€ Can it run independently?
â”‚  â”œâ”€ NO â†’ Consider combining with related stage
â”‚  â””â”€ YES â†’ Continue
â”‚
â”œâ”€ Does it need separate logging/manifest?
â”‚  â”œâ”€ NO â†’ Might be a helper function
â”‚  â””â”€ YES â†’ Continue
â”‚
â”œâ”€ Would it create excessive I/O overhead?
â”‚  â”œâ”€ YES â†’ Consider combining stages
â”‚  â””â”€ NO â†’ âœ… CREATE NEW STAGE
â”‚
â””â”€ If YES to all: Follow Â§ 3.1 pattern
```

### What Type of Error Handling Do I Need?

```
Error type:
â”œâ”€ File not found â†’ FileNotFoundError + logger.error()
â”œâ”€ Permission denied â†’ PermissionError + logger.error()
â”œâ”€ Invalid config â†’ ValueError + logger.error()
â”œâ”€ Network/API â†’ OSError/RequestException + retry logic
â”œâ”€ Data validation â†’ ValueError + descriptive message
â””â”€ Unknown â†’ Exception + exc_info=True

Always:
â”œâ”€ Log with logger.error(..., exc_info=True)
â”œâ”€ Provide context in message
â””â”€ Re-raise or return error code
```

### Where Should This Output Go?

```
Output destination:
â”œâ”€ Stage processing result?
â”‚  â””â”€ âœ… io.stage_dir / "filename.ext"
â”‚
â”œâ”€ Temporary/scratch file?
â”‚  â””â”€ âœ… io.stage_dir / "temp" / "file.ext"
â”‚
â”œâ”€ Final pipeline output?
â”‚  â””â”€ âŒ Write to io.stage_dir, pipeline copies to out/
â”‚
â”œâ”€ Shared between stages?
â”‚  â””â”€ âŒ Each stage writes own copy, use manifests
â”‚
â””â”€ NEVER:
    â”œâ”€ job_dir / "file" (breaks isolation)
    â”œâ”€ /tmp/ (unreliable)
    â””â”€ other_stage_dir/ (breaks data lineage)
```

---

## ğŸ“š Topical Index

### By Component

**Configuration (Â§ 4)**
- Adding parameters â†’ Â§ 4.1, Â§ 4.2
- Loading config â†’ Â§ 4.2
- Type conversion â†’ Â§ 4.3, Â§ 4.4
- Secrets handling â†’ Â§ 4.6
- Validation â†’ Â§ 4.7

**Logging (Â§ 2)**
- Basic logging â†’ Â§ 2.3
- Stage logs â†’ Â§ 2.4
- Log levels â†’ Â§ 2.3.2
- Performance logging â†’ Â§ 2.3.4
- Error logging â†’ Â§ 2.3.5

**Stages (Â§ 3)**
- Creating new stage â†’ Â§ 3.1
- StageIO pattern â†’ Â§ 2.6
- Input handling â†’ Â§ 3.2
- Output tracking â†’ Â§ 3.3
- Dependencies â†’ Â§ 3.4

**Data Tracking (Â§ 2)**
- Manifests â†’ Â§ 2.5
- Input tracking â†’ Â§ 2.5.3
- Output tracking â†’ Â§ 2.5.4
- Data lineage â†’ Â§ 2.8
- Hash computation â†’ Â§ 2.5.2

**Code Quality (Â§ 6)**
- Import organization â†’ Â§ 6.1
- Type hints â†’ Â§ 6.2
- Docstrings â†’ Â§ 6.3
- Function patterns â†’ Â§ 6.4
- Testing â†’ Â§ 7

### By Task

**I need to...**
- ...add a stage â†’ Â§ 3.1, Decision Tree #1
- ...log something â†’ Â§ 2.3, Critical Rule #1
- ...handle errors â†’ Â§ 5, Decision Tree #2
- ...add config â†’ Â§ 4.1, Â§ 4.2
- ...track files â†’ Â§ 2.5
- ...organize imports â†’ Â§ 6.1, Critical Rule #2
- ...write outputs â†’ Â§ 1.1, Decision Tree #3
- ...validate data â†’ Â§ 5, Â§ 7.2

### By Problem

**Common Issues:**
- "Print not working" â†’ Use logger (Â§ 2.3)
- "Output not found" â†’ Check io.stage_dir (Â§ 1.1)
- "Manifest error" â†’ enable_manifest=True (Â§ 2.6)
- "Config not loading" â†’ Use load_config() (Â§ 4.2)
- "Import error" â†’ Organize properly (Â§ 6.1)
- "Permission denied" â†’ Error handling (Â§ 5)
- "File not tracked" â†’ add_input/output (Â§ 2.5)

---

## ğŸ“‚ File Naming Standards

### Stage Script Naming (MANDATORY)

**All stage scripts MUST follow this pattern:**

```
scripts/{NN}_{stage_name}.py
```

Where `NN` is the stage number (01-99) and matches the stage directory name.

**Examples:**

âœ… **CORRECT:**
```
scripts/01_demux.py           â†’ Stage directory: 01_demux/
scripts/02_tmdb_enrichment.py â†’ Stage directory: 02_tmdb/
scripts/03_glossary_loader.py â†’ Stage directory: 03_glossary_load/
scripts/04_source_separation.py
scripts/05_pyannote_vad.py
scripts/06_whisperx_asr.py
scripts/07_mlx_alignment.py (or 07_alignment.py)
scripts/08_indictrans2_translation.py (or 08_translate.py)
scripts/09_subtitle_generation.py (or 09_subtitle_gen.py)
scripts/10_mux.py
```

âŒ **INCORRECT (Old patterns - DO NOT USE):**
```
scripts/demux.py                          # Missing stage number
scripts/tmdb_enrichment_stage.py          # Wrong name (fixed in v6.1)
scripts/03_glossary_load/glossary_loader.py  # Wrong directory
```

**Rules:**
1. âœ… Format: `{NN}_{stage_name}.py`
2. âœ… Place directly in `scripts/` (not in subdirectories)
3. âœ… Match stage directory name (e.g., `01_demux/` â†’ `01_demux.py`)
4. âŒ No `_stage` suffix
5. âŒ No subdirectories for stage scripts

**Utility Scripts (Non-stages):**
```
scripts/config_loader.py      # Helper modules
scripts/device_selector.py
scripts/filename_parser.py
```

---

## ğŸ”§ Job Preparation Flow

### prepare-job Design

**Purpose:** Create job-specific configuration by copying and customizing system defaults.

**Process Flow:**

```
1. Read: config/.env.pipeline (system defaults)
   â†“
2. Create: out/.../job-YYYYMMDD-user-NNNN/ (job directory)
   â†“
3. Copy: config/.env.pipeline â†’ job/.env.pipeline
   â†“
4. Update: job/.env.pipeline with CLI parameters
   â†“
5. Create: job/job.json (job metadata)
```

**Example:**

```bash
./prepare-job.sh --media in/movie.mp4 --workflow subtitle \
  --source-language hi --target-language en

# Results in:
# 1. job/.env.pipeline (copied from config/.env.pipeline)
# 2. job/.env.pipeline updated with: source_language=hi, target_language=en
# 3. job/job.json created with job metadata
```

**Configuration Files:**

1. **`config/.env.pipeline`** (System defaults)
   - Created by `bootstrap.sh`
   - Version-controlled template
   - Default values for all parameters
   - **NEVER modified during job execution**

2. **`{job_dir}/.env.pipeline`** (Job-specific config)
   - Created by `prepare-job` (copied from system defaults)
   - Updated with CLI parameters
   - Used by all stages during execution
   - Not version-controlled

3. **`{job_dir}/job.json`** (Job metadata)
   - Job ID, workflow, languages, timestamps
   - Created by `prepare-job`
   - Metadata only (not loaded by stages)

**Stage Configuration Access:**

```python
from shared.config_loader import load_config

# In stage scripts:
def run_stage(job_dir: Path, stage_name: str) -> int:
    # Automatically reads from job_dir/.env.pipeline
    config = load_config(job_dir)
    
    # Get configuration values
    model = config.get("WHISPERX_MODEL", "large-v2")
    enabled = config.get("SOURCE_SEPARATION_ENABLED", "true")
```

**Key Points:**
- âœ… `prepare-job` copies config, doesn't read CLI params from job.json
- âœ… Stages read `.env.pipeline`, not `job.json`
- âœ… System config (`config/.env.pipeline`) is never modified
- âœ… Each job has its own `.env.pipeline` copy

---

## ğŸš¨ Critical Rules (NEVER Violate)

### 1. Logger Usage - NOT Print (Â§ 2.3)

**60% of files violate this - Priority #1 fix**

âŒ **DON'T:** `print("message")`

âœ… **DO:**
```python
# Stages
io = StageIO("stage", job_dir, enable_manifest=True)
logger = io.get_stage_logger()

# Non-stages
from shared.logger import get_logger
logger = get_logger(__name__)

# Usage
logger.debug("Diagnostic info")
logger.info("General info")
logger.warning("Unexpected situation")
logger.error("Error occurred", exc_info=True)
logger.critical("Severe error")
```

---

### 2. Import Organization (Â§ 6.1)

**100% of files violate this - Priority #2 fix**

âŒ **DON'T:** Mix import groups

âœ… **DO:**
```python
# Standard library
import os
import sys
from pathlib import Path

# Third-party
import numpy as np

# Local
from shared.config import load_config
```

**Order:** Standard â†’ Third-party â†’ Local (blank lines between)

---

### 3. StageIO Pattern (Â§ 2.6)

**Every stage MUST:**

```python
#!/usr/bin/env python3
# Standard library
import sys
from pathlib import Path

# Local
sys.path.insert(0, str(Path(__file__).parent.parent))
from shared.config_loader import load_config
from shared.stage_utils import StageIO

def run_stage(job_dir: Path, stage_name: str = "stage") -> int:
    # 1. Initialize with manifest
    io = StageIO(stage_name, job_dir, enable_manifest=True)
    logger = io.get_stage_logger()
    
    try:
        # 2. Load config
        config = load_config()
        
        # 3. Find input
        input_file = io.job_dir / "prev_stage" / "input.ext"
        io.manifest.add_input(input_file, io.compute_hash(input_file))
        
        # 4. Define output in stage dir ONLY
        output_file = io.stage_dir / "output.ext"
        
        # 5. Process
        logger.info("Processing...")
        
        # 6. Track output
        io.manifest.add_output(output_file, io.compute_hash(output_file))
        
        # 6a. Track intermediate files (NEW in v6.1)
        intermediate_file = io.stage_dir / "cache.tmp"
        io.track_intermediate(intermediate_file, retained=True, reason="Model cache")
        
        # 7. Finalize
        io.finalize_stage_manifest(exit_code=0)
        return 0
        
    except Exception as e:
        logger.error(f"Failed: {e}", exc_info=True)
        io.finalize_stage_manifest(exit_code=1)
        return 1
```

**Must have:**
- `enable_manifest=True`
- `io.get_stage_logger()` (not print)
- Track inputs/outputs
- Track intermediate files (NEW in v6.1) - Use `io.track_intermediate()` for cache/temp files
- Write to `io.stage_dir` ONLY
- Finalize manifest

**StageManifest Methods (v6.1):**
```python
# Track inputs
io.manifest.add_input("key", file_path, "description")

# Track outputs  
io.manifest.add_output("key", file_path, "description")

# Track intermediate files (NEW in v6.1)
io.track_intermediate(file_path, retained=True, reason="Model cache")
# retained=True: Keep after stage completes
# retained=False: Temporary file (can be deleted)
```

---

### 4. Configuration (Â§ 4)

âŒ **DON'T:** `os.getenv()` or `os.environ[]`

âœ… **DO:**
```python
from shared.config_loader import load_config

config = load_config()
value = int(config.get("PARAM_NAME", default))
```

**Steps:**
1. Add to `config/.env.pipeline` with full documentation
2. Use `load_config()`
3. Provide default with `.get(key, default)`
4. Convert types: int(), float(), bool()

**Configuration Parameter Rules:**
- âœ… **Implement feature FIRST, then add parameter**
- âœ… **Remove unused parameters immediately**  
- âœ… **Mark future features**: `Status: â³ NOT YET IMPLEMENTED`
- âœ… **Full documentation**: Purpose, values, defaults, impact
- âŒ **NEVER add without implementation**
- âŒ **NEVER leave unused parameters**

---

### 5. Error Handling (Â§ 5)

```python
try:
    risky_operation()
except FileNotFoundError as e:
    logger.error(f"File not found: {e}", exc_info=True)
    raise
except PermissionError as e:
    logger.error(f"Permission denied: {e}", exc_info=True)
    raise
except Exception as e:
    logger.error(f"Unexpected: {e}", exc_info=True)
    raise RuntimeError(f"Failed: {e}")
```

**Key:** Specific exceptions first, always `exc_info=True`

**âš ï¸ COMMON MISTAKE - AVOID:**
```python
# âŒ WRONG - Duplicate parameter (SyntaxError)
logger.error(f"Error: {e}", exc_info=True, exc_info=True)

# âœ… CORRECT - Single parameter
logger.error(f"Error: {e}", exc_info=True)
```

**Note:** This error occurred in job-20251203-rpatel-0015 and caused pipeline failure. Always use `exc_info=True` exactly once.

---

### 6. Stage Directory Containment (Â§ 1.1)

âŒ **DON'T:**
```python
output = job_dir / "file.ext"  # Wrong: job root
output = Path("/tmp/file.ext")  # Wrong: /tmp
```

âœ… **DO:**
```python
output = io.stage_dir / "file.ext"  # Correct: stage dir only
```

---

## ğŸ–¥ï¸ Cross-Platform Requirements (Â§ 1.2)

**ALL core scripts MUST have Windows equivalents:**

| Script | Unix/macOS | Windows | Status |
|--------|------------|---------|--------|
| bootstrap | âœ… `.sh` | âœ… `.ps1` | Complete |
| prepare-job | âœ… `.sh` | âœ… `.ps1` | Complete |
| run-pipeline | âœ… `.sh` | âœ… `.ps1` | Complete |
| test-glossary-quickstart | âœ… `.sh` | âœ… `.ps1` | Complete |

**When creating NEW shell scripts:**
1. Create `.sh` for Unix/Linux/macOS
2. Create `.ps1` for Windows (PowerShell 5.1+)
3. Test on both platforms or document limitations
4. Use platform-agnostic patterns where possible

**Python code MUST be cross-platform:**
```python
# âœ… GOOD - Cross-platform paths
from pathlib import Path
config_path = Path("config") / ".env.pipeline"

# âŒ BAD - Unix-only
config_path = "config/.env.pipeline"

# âœ… GOOD - Platform detection
import sys
if sys.platform == "win32":
    # Windows-specific code
else:
    # Unix-like systems
```

---

## ğŸ“‹ Pre-Commit Checklist

**Before proposing code, verify:**

**ALL code:**
- [ ] Logger, not print (Â§ 2.3)
- [ ] Imports organized (Â§ 6.1)
- [ ] Type hints (Â§ 6.2)
- [ ] Docstrings (Â§ 6.3)
- [ ] Error handling (Â§ 5)
- [ ] Cross-platform compatible (Â§ 1.2)

**STAGE code:**
- [ ] File named `{NN}_{stage_name}.py` (File Naming)
- [ ] File in `scripts/` directory (not subdirectory)
- [ ] `enable_manifest=True` (Â§ 2.6)
- [ ] `io.get_stage_logger()` (Â§ 2.3)
- [ ] Track inputs (Â§ 2.5)
- [ ] Track outputs (Â§ 2.5)
- [ ] Write to `io.stage_dir` only (Â§ 1.1)
- [ ] Finalize manifest (Â§ 2.6)
- [ ] Context propagation implemented (Â§ 1.5) ğŸ†•
- [ ] Cache-aware processing (Â§ 1.6) ğŸ†•

**TEST code:** ğŸ†•
- [ ] Uses standard test media (Â§ 1.4)
- [ ] Tests Sample 1 (English technical) OR Sample 2 (Hinglish)
- [ ] Validates quality baselines
- [ ] Tests relevant workflow (Subtitle/Transcribe/Translate)
- [ ] Tests caching behavior (first run vs. cached)
- [ ] Includes integration test if workflow modified

**SHELL scripts:**
- [ ] Unix (.sh) script created
- [ ] Windows (.ps1) script created
- [ ] Both scripts have same functionality
- [ ] Both scripts tested (or documented as untested)

**CONFIG changes:**
- [ ] Parameter is actually USED in code (not planned)
- [ ] Searched codebase to confirm usage
- [ ] Added to `.env.pipeline` with full documentation (Â§ 4.1)
- [ ] Uses `load_config()` in code (Â§ 4.2)
- [ ] Has default value (Â§ 4.3)
- [ ] If future feature: Marked with `â³ NOT YET IMPLEMENTED`

**Dependencies:**
- [ ] Added to `requirements/*.txt` (Â§ 1.3)

**Run automated checker:**
```bash
./scripts/validate-compliance.py your_file.py
```

---

## ğŸ¯ Common Patterns

### Multiple Inputs
```python
for f in input_dir.glob("*.wav"):
    io.manifest.add_input(f, io.compute_hash(f))
```

### Config Types
```python
config = load_config()
int_val = int(config.get("MAX_DURATION", 3600))
float_val = float(config.get("THRESHOLD", 0.85))
bool_val = config.get("ENABLED", "true").lower() == "true"
list_val = config.get("LANGS", "en,hi").split(",")
```

### Progress Logging
```python
for i, item in enumerate(items):
    if i % 100 == 0:
        logger.info(f"Progress: {i}/{len(items)} ({i/len(items)*100:.0f}%)")
```

### Performance Logging
```python
import time
start = time.time()
result = expensive_op()
logger.info(f"Completed in {time.time()-start:.2f}s")
```

---

## ğŸ—ï¸ Tech Stack

- **Python:** 3.11+
- **Stages:** 01_demux, 02_tmdb, etc.
- **I/O:** `shared/stage_utils.py`
- **Config:** `config/.env.pipeline`
- **Logging:** Main + stage logs

---

## ğŸ”— References

**Complete standards:** `docs/developer/DEVELOPER_STANDARDS.md`

**Sections:**
- Â§ 1: Project structure
- Â§ 2: Logging & manifests
- Â§ 3: Stages
- Â§ 4: Configuration
- Â§ 5: Error handling
- Â§ 6: Code style
- Â§ 7: Testing

**Guides:**
- **`docs/CODE_EXAMPLES.md`** - â­ Good vs Bad code examples (941 lines)
- `docs/developer-guide.md` - Onboarding
- `docs/BASELINE_COMPLIANCE_METRICS.md` - Current state
- `docs/AI_MODEL_ROUTING.md` - Model selection

---

## ğŸ¤– Automated Validation

**Pre-commit Hook: âœ… ACTIVE**

The pre-commit hook automatically validates all staged Python files:
```bash
# Hook runs automatically on commit
git commit -m "Your message"
# â†’ Hook validates Python files
# â†’ Blocks if violations found
# â†’ Commits if all pass
```

**Manual Validation:**
```bash
# Single file
python3 scripts/validate-compliance.py scripts/your_stage.py

# Multiple files
python3 scripts/validate-compliance.py scripts/*.py

# Strict mode (exit 1 on violations)
python3 scripts/validate-compliance.py --strict scripts/*.py

# Check staged files
python3 scripts/validate-compliance.py --staged
```

**Hook Setup (for new clones):**
```bash
cp tools/pre-commit-hook-template.sh .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

**Full Guide:** `docs/PRE_COMMIT_HOOK_GUIDE.md`

---

## ğŸ“Š Status

**Achievement:** ğŸŠ **100% PERFECT COMPLIANCE** ğŸŠ

**All Categories (100%):**
- âœ… Type hints: 100% (140+ added)
- âœ… Docstrings: 100% (80+ added)
- âœ… Logger usage: 100% (no print statements)
- âœ… Import organization: 100% (Standard/Third-party/Local)
- âœ… Config patterns: 100% (load_config() everywhere)
- âœ… Error handling: 100% (proper try/except)

**Files:** 69/69 (100% compliant) | **Violations:** 0 critical, 0 errors, 0 warnings

---

## ğŸš€ Testing

- Tests in `tests/`
- Run: `pytest tests/`
- Unit: fast (no GPU)
- Coverage: `pytest --cov`

---

**When in doubt:**
1. Run the mental checklist at the top
2. Use decision trees above
3. **Check CODE_EXAMPLES.md for visual examples** â­
4. Check Â§ reference in DEVELOPER_STANDARDS.md
5. Run `validate-compliance.py` on your code
6. **Commit will be blocked if violations exist** ğŸ”’

**Version:** 4.0 (100% Compliance) | **Lines:** 500+ | **Status:** âœ… PERFECT | **Automated:** âœ…
