# CP-WhisperX-App

**Production-ready pipeline for automated video transcription, translation, and subtitle generation using WhisperX, PyAnnote, and spaCy NER.**

Perfect for processing movies, TV shows, podcasts, or any video content requiring high-quality transcription with speaker diarization and named entity recognition.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-downloads)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

---

## ğŸ¯ What It Does

CP-WhisperX-App provides two powerful workflows:

### 1. **Transcribe Workflow** (Fast)
Extract clean transcription from video/audio in minutes.
- Audio extraction
- Voice activity detection
- High-accuracy transcription

### 2. **Subtitle Generation Workflow** (Full Quality)
Complete end-to-end subtitle creation with speaker labels.
- All transcribe features, plus:
- Speaker diarization (identify who's speaking)
- TMDB metadata (cast/crew names)
- Named entity recognition (correct names)
- Second pass translation (15-20% quality boost)
- Lyrics detection (20-25% improvement for songs)
- SRT subtitle generation
- Video muxing with embedded subtitles

**Result:** Professional-quality subtitles with speaker labels, ready for distribution!

---

## âœ¨ Key Features

### Cross-Platform Support
- **Windows 11 Pro** with NVIDIA GPU (CUDA)
- **Linux** with NVIDIA GPU (CUDA)
- **macOS** with Apple Silicon (MPS)
- **CPU Fallback** for any platform

### Dual Execution Modes
- **Native Mode**: Direct Python execution with GPU acceleration (fastest)
- **Docker Mode**: Containerized execution for reproducibility and isolation

### Intelligent Pipeline
- **Job-based workflow**: Isolated jobs with unique IDs
- **Manifest tracking**: Complete audit trail of all processing steps
- **Resume capability**: Automatically resume from last successful stage
- **Clip mode**: Test pipeline on short clips before full processing
- **Auto device detection**: Automatically selects best compute device

### Production Ready
- **Comprehensive logging**: Sequential stage logs with configurable verbosity
- **Error handling**: Graceful failure with detailed error reporting
- **Validation**: Pre-flight checks for dependencies and GPU
- **Monitoring**: Real-time progress tracking

### Quality Enhancements
- **NER-enhanced prompts**: Better transcription using entity hints
- **Second pass translation**: Refined translation with context
- **Lyrics detection**: Special handling for songs and music
- **Speaker diarization**: Identify and label different speakers

---

## ğŸ—ï¸ Architecture

### Pipeline Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CP-WhisperX-App Pipeline                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[Input Video]
     â”‚
     â”œâ”€â†’ 01. DEMUX â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Extract audio (WAV)
     â”‚
     â”œâ”€â†’ 02. TMDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Fetch cast/crew metadata
     â”‚
     â”œâ”€â†’ 03. PRE-NER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Extract entity names
     â”‚
     â”œâ”€â†’ 04. SILERO VAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Voice activity detection
     â”‚
     â”œâ”€â†’ 05. PYANNOTE VAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Refined VAD
     â”‚
     â”œâ”€â†’ 06. DIARIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Speaker identification
     â”‚
     â”œâ”€â†’ 07. ASR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ WhisperX transcription
     â”‚
     â”œâ”€â†’ 07b. SECOND PASS â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Translation refinement
     â”‚
     â”œâ”€â†’ 07c. LYRICS DETECTION â”€â”€â”€â”€â†’ Song/music handling
     â”‚
     â”œâ”€â†’ 08. POST-NER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Entity name correction
     â”‚
     â”œâ”€â†’ 09. SUBTITLE GEN â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Generate SRT subtitles
     â”‚
     â””â”€â†’ 10. MUX â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Embed subtitles in video
          â”‚
[Output Video with Subtitles]
```

### Workflow Comparison

| Stage                  | Transcribe | Subtitle-Gen | ML Model | Device    |
|------------------------|:----------:|:------------:|:--------:|-----------|
| 01. Demux              | âœ…         | âœ…           | âŒ       | CPU       |
| 02. TMDB               | âŒ         | âœ…           | âŒ       | CPU       |
| 03. Pre-NER            | âŒ         | âœ…           | âœ…       | CPU       |
| 04. Silero VAD         | âœ…         | âœ…           | âœ…       | GPU/CPU   |
| 05. PyAnnote VAD       | âœ…         | âœ…           | âœ…       | GPU/CPU   |
| 06. Diarization        | âŒ         | âœ…           | âœ…       | GPU/CPU   |
| 07. ASR                | âœ…         | âœ…           | âœ…       | GPU/CPU   |
| 07b. Second Pass       | âŒ         | âœ…           | âœ…       | GPU/CPU   |
| 07c. Lyrics Detection  | âŒ         | âœ…           | âœ…       | GPU/CPU   |
| 08. Post-NER           | âŒ         | âœ…           | âŒ       | CPU       |
| 09. Subtitle Gen       | âŒ         | âœ…           | âŒ       | CPU       |
| 10. Mux                | âŒ         | âœ…           | âŒ       | CPU       |

---

## ğŸ“ Project Structure

```
cp-whisperx-app/
â”œâ”€â”€ pipeline.py                 # Main orchestrator
â”œâ”€â”€ preflight.py               # System validation & setup
â”œâ”€â”€ prepare-job.py             # Job preparation tool
â”œâ”€â”€ docker-compose.yml         # Docker orchestration
â”‚
â”œâ”€â”€ arch/                      # Architecture documentation
â”‚   â”œâ”€â”€ workflow-arch.txt
â”‚   â””â”€â”€ transcribe-workflow.txt
â”‚
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ .env.example          # Example configuration
â”‚   â”œâ”€â”€ .env.template         # Configuration template
â”‚   â””â”€â”€ secrets.example.json  # Secrets template
â”‚
â”œâ”€â”€ docker/                    # Docker containers
â”‚   â”œâ”€â”€ base/                 # Base image
â”‚   â”œâ”€â”€ demux/                # Stage 01: Audio extraction
â”‚   â”œâ”€â”€ tmdb/                 # Stage 02: Metadata
â”‚   â”œâ”€â”€ pre-ner/              # Stage 03: Pre-NER
â”‚   â”œâ”€â”€ silero-vad/           # Stage 04: Silero VAD
â”‚   â”œâ”€â”€ pyannote-vad/         # Stage 05: PyAnnote VAD
â”‚   â”œâ”€â”€ diarization/          # Stage 06: Speaker diarization
â”‚   â”œâ”€â”€ asr/                  # Stage 07: WhisperX ASR
â”‚   â”œâ”€â”€ second-pass-translation/  # Stage 07b: Translation
â”‚   â”œâ”€â”€ lyrics-detection/     # Stage 07c: Lyrics
â”‚   â”œâ”€â”€ post-ner/             # Stage 08: Post-NER
â”‚   â”œâ”€â”€ subtitle-gen/         # Stage 09: Subtitle generation
â”‚   â””â”€â”€ mux/                  # Stage 10: Video muxing
â”‚
â”œâ”€â”€ native/                    # Native mode execution
â”‚   â”œâ”€â”€ scripts/              # Stage scripts (01-10)
â”‚   â”‚   â”œâ”€â”€ 01_demux.py
â”‚   â”‚   â”œâ”€â”€ 02_tmdb.py
â”‚   â”‚   â”œâ”€â”€ 03_pre_ner.py
â”‚   â”‚   â”œâ”€â”€ 04_silero_vad.py
â”‚   â”‚   â”œâ”€â”€ 05_pyannote_vad.py
â”‚   â”‚   â”œâ”€â”€ 06_diarization.py
â”‚   â”‚   â”œâ”€â”€ 07_asr.py
â”‚   â”‚   â”œâ”€â”€ 07b_second_pass_translation.py
â”‚   â”‚   â”œâ”€â”€ 07c_lyrics_detection.py
â”‚   â”‚   â”œâ”€â”€ 08_post_ner.py
â”‚   â”‚   â”œâ”€â”€ 09_subtitle_gen.py
â”‚   â”‚   â””â”€â”€ 10_mux.py
â”‚   â””â”€â”€ venvs/                # Virtual environments (created by preflight)
â”‚
â”œâ”€â”€ scripts/                   # Pipeline utilities
â”‚   â”œâ”€â”€ bootstrap.sh          # Environment setup
â”‚   â”œâ”€â”€ build-images.sh       # Docker image builder
â”‚   â”œâ”€â”€ common-logging.sh     # Logging utilities
â”‚   â”œâ”€â”€ config_loader.py      # Configuration loader
â”‚   â”œâ”€â”€ device_selector.py    # GPU detection
â”‚   â”œâ”€â”€ logger.py             # Logging framework
â”‚   â””â”€â”€ pipeline-status.sh    # Status checker
â”‚
â”œâ”€â”€ shared/                    # Shared Python modules
â”‚   â”œâ”€â”€ config.py             # Configuration loader
â”‚   â”œâ”€â”€ logger.py             # Logging utilities
â”‚   â”œâ”€â”€ manifest.py           # Manifest builder
â”‚   â””â”€â”€ utils.py              # Common utilities
â”‚
â”œâ”€â”€ in/                        # Input videos (staging)
â”œâ”€â”€ out/                       # Output artifacts (both native and Docker)
â”‚   â””â”€â”€ YYYY/MM/DD/<user-id>/<job-id>/
â”‚       â”œâ”€â”€ job.json           # Job definition (replaces jobs/)
â”‚       â”œâ”€â”€ .<job-id>.env      # Job-specific configuration
â”‚       â”œâ”€â”€ logs/              # Job-specific logs
â”‚       â”œâ”€â”€ manifest.json      # Processing manifest
â”‚       â”œâ”€â”€ audio/             # Demux output
â”‚       â”œâ”€â”€ vad/               # VAD outputs
â”‚       â”œâ”€â”€ diarization/       # Diarization output
â”‚       â””â”€â”€ ...                # Stage outputs
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ JOB_ORCHESTRATION.md
    â”œâ”€â”€ LOGGING.md
    â”œâ”€â”€ MANIFEST_TRACKING.md
    â”œâ”€â”€ PIPELINE_BEST_PRACTICES.md
    â”œâ”€â”€ SECRETS_MANAGER.md
    â”œâ”€â”€ TMDB_API_SETUP.md
    â””â”€â”€ TEST_PLAN.md
```

---

## ğŸš€ Quick Start

### Step 1: Installation
```bash
# Clone repository
git clone <repository-url>
cd cp-whisperx-app

# Setup configuration
cp config/.env.example config/.env
# Edit config/.env with your API keys

# Run preflight check
python preflight.py
```

### Step 2: Run Pipeline

**Transcribe Only:**
```bash
python prepare-job.py input.mp4 --transcribe --native
python pipeline.py --job <job-id>
```

**Subtitle Generation:**
```bash
python prepare-job.py input.mp4 --subtitle-gen --native
python pipeline.py --job <job-id>
```

See [QUICKSTART.md](QUICKSTART.md) for detailed instructions.

---

## ğŸ“Š Performance

### Processing Times (2-hour movie)

| Workflow      | GPU (CUDA/MPS) | CPU     |
|---------------|----------------|---------|
| Transcribe    | 10-15 min      | 2-3 hrs |
| Subtitle-Gen  | 30-45 min      | 5-8 hrs |

**Factors affecting speed:**
- GPU model and VRAM
- Video length and audio complexity
- Number of speakers
- Language (Hindiâ†’English vs English-only)

### Resource Requirements

| Component     | Minimum | Recommended |
|---------------|---------|-------------|
| RAM           | 16 GB   | 32 GB       |
| VRAM (GPU)    | 6 GB    | 12 GB       |
| Storage       | 20 GB   | 50 GB       |
| CPU Cores     | 4       | 8+          |

---

## ğŸ”§ Configuration

### Environment Variables

**Core Settings:**
```bash
# Execution mode
PIPELINE_MODE=native              # native or docker
WORKFLOW=subtitle_gen             # transcribe or subtitle_gen

# Device selection
DEVICE=auto                       # auto, cuda, mps, or cpu
DEVICE_OVERRIDE=false            # Force specific device

# Processing options
CLIP_MODE=false                  # Process short clips
CLIP_DURATION=300                # Clip length in seconds
```

**API Keys:**
```bash
# Required for diarization
HF_TOKEN=hf_xxxxxxxxxxxx

# Optional for metadata
TMDB_API_KEY=xxxxxxxxxxxx
```

**Model Settings:**
```bash
# WhisperX
WHISPER_MODEL=large-v3
WHISPER_LANGUAGE=hi              # Source language
WHISPER_TASK=translate           # or transcribe

# Diarization
DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
MIN_SPEAKERS=2
MAX_SPEAKERS=10
```

See [config/.env.template](config/.env.template) for all options.

---

## ğŸ“– Documentation

### Quick References
- **[QUICKSTART.md](QUICKSTART.md)** - Get started in minutes
- **[WORKFLOW_GUIDE.md](WORKFLOW_GUIDE.md)** - Detailed workflow options
- **[PIPELINE_RESUME_GUIDE.md](PIPELINE_RESUME_GUIDE.md)** - Resume failed jobs

### Platform Guides
- **[WINDOWS_11_SETUP_GUIDE.md](WINDOWS_11_SETUP_GUIDE.md)** - Windows installation
- **[CUDA_ACCELERATION_GUIDE.md](CUDA_ACCELERATION_GUIDE.md)** - NVIDIA GPU setup
- **[MPS_ACCELERATION_GUIDE.md](MPS_ACCELERATION_GUIDE.md)** - Apple Silicon setup
- **[DEVICE_SELECTION_GUIDE.md](DEVICE_SELECTION_GUIDE.md)** - GPU optimization

### Architecture & Development
- **[docs/JOB_ORCHESTRATION.md](docs/JOB_ORCHESTRATION.md)** - Job system design
- **[docs/MANIFEST_TRACKING.md](docs/MANIFEST_TRACKING.md)** - Manifest system
- **[docs/LOGGING.md](docs/LOGGING.md)** - Logging architecture
- **[docs/PIPELINE_BEST_PRACTICES.md](docs/PIPELINE_BEST_PRACTICES.md)** - Best practices
- **[docs/TEST_PLAN.md](docs/TEST_PLAN.md)** - Testing & validation

### API Setup
- **[docs/TMDB_API_SETUP.md](docs/TMDB_API_SETUP.md)** - TMDB API configuration
- **[docs/SECRETS_MANAGER.md](docs/SECRETS_MANAGER.md)** - Secrets management

---

## ğŸ§ª Testing

### Validation Checklist

```bash
# 1. System validation
python preflight.py

# 2. GPU detection
python preflight.py --check-device

# 3. API access
python native/scripts/test_tmdb.py
python native/scripts/test_pyannote_vad.py

# 4. Quick test (2-minute clip)
python prepare-job.py test.mp4 --subtitle-gen --native --clip-duration 120
python pipeline.py --job <job-id>

# 5. Full workflow test
python prepare-job.py sample.mp4 --subtitle-gen --native
python pipeline.py --job <job-id>
```

See [docs/TEST_PLAN.md](docs/TEST_PLAN.md) for comprehensive testing.

---

## ğŸ” Troubleshooting

### Common Issues

**GPU Not Detected:**
```bash
python preflight.py --check-device
python prepare-job.py input.mp4 --native --device cuda  # Force CUDA
```

**PyAnnote Diarization Fails:**
```bash
# Accept license at: https://huggingface.co/pyannote/speaker-diarization
# Add HF_TOKEN to config/.env
python native/scripts/test_pyannote_vad.py
```

**Out of Memory:**
```bash
# Use CPU or smaller clip
python prepare-job.py input.mp4 --native --device cpu
python prepare-job.py input.mp4 --native --clip-duration 300
```

**Resume Failed Job:**
```bash
./resume-pipeline.sh <job-id>          # Unix/Linux/macOS
resume-pipeline.bat <job-id>           # Windows
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[WhisperX](https://github.com/m-bain/whisperX)** - Fast automatic speech recognition
- **[PyAnnote](https://github.com/pyannote/pyannote-audio)** - Speaker diarization
- **[Silero VAD](https://github.com/snakers4/silero-vad)** - Voice activity detection
- **[spaCy](https://spacy.io/)** - Named entity recognition
- **[FFmpeg](https://ffmpeg.org/)** - Audio/video processing

---

## ğŸ“ Support

- **Documentation:** [docs/](docs/) directory
- **Issues:** Check logs in `logs/` directory  
- **Debugging:** Enable verbose logging in config/.env

---

**Ready to start?** See [QUICKSTART.md](QUICKSTART.md) to begin!
