# CP-WhisperX-App vs IMPROVEMENT-PLAN.md - Gap Analysis
**Date**: November 9, 2025  
**Status**: Current Implementation Analysis

---

## Executive Summary

The **CP-WhisperX-App** project implements approximately **85-90%** of the improvement plan's vision with strong fundamentals in pipeline architecture, VAD/ASR/diarization, and automation. The main gaps are in:
1. **Glossary/terminology management** (human-editable TSV system)
2. **Human-in-the-loop QA workflow** (reviewer tools)
3. **Advanced post-editing rules** (context-aware NLG)
4. **Per-film memory/prompts** (catchphrase tracking)

---

## Implementation Status by Section

### ‚úÖ Step 1: Goals & Success Criteria (95% COMPLETE)

**Implemented**:
- ‚úÖ Subtitle readability targets configured
  - `SUBTITLE_MAX_LINE_LENGTH=42`
  - `SUBTITLE_MAX_LINES=2`
  - `SUBTITLE_MAX_DURATION=7.0`
- ‚úÖ Quality metrics tracking in logs
- ‚úÖ Performance optimization (GPU acceleration, MPS support)

**Gaps**:
- ‚ö†Ô∏è CPS (characters per second) target not enforced at 15 (cap 17)
- ‚ö†Ô∏è MER (Mixed Error Rate) not actively measured
- ‚ö†Ô∏è No JSON metrics config file as specified

**Evidence**:
```python
# shared/config.py (lines 124-130)
subtitle_max_line_length: int = Field(default=42)
subtitle_max_lines: int = Field(default=2)
subtitle_max_duration: float = Field(default=7.0)
subtitle_merge_short: bool = Field(default=True)
```

---

### ‚úÖ Step 2: Film Curation (80% COMPLETE)

**Implemented**:
- ‚úÖ TMDB integration for metadata (`docker/tmdb/`)
- ‚úÖ Job-based organization (`out/YYYY/MM/DD/USER/JOBID/`)
- ‚úÖ Supports 1990s & 2000s Bollywood films

**Gaps**:
- ‚ö†Ô∏è No curated film catalog YAML
- ‚ö†Ô∏è No per-film notes/prompts system
- ‚ö†Ô∏è Manual job creation (no batch processing)

**Recommendation**:
Create `config/film_catalog.yaml`:
```yaml
catalog:
  - title: "Jaane Tu Ya Jaane Na"
    year: 2008
    tmdb_id: 12345
    notes: "Friend-group colloquialisms; Mumbai urban youth"
    prompts_file: "glossary/prompts/jaane_tu.txt"
```

---

### ‚úÖ Step 3: Data Acquisition & Preparation (100% COMPLETE) ‚≠ê

**Implemented**:
- ‚úÖ `docker/demux/demux.py` - Audio extraction
  ```python
  '-ar', '16000',  # 16kHz sample rate
  '-ac', '1',      # Mono
  '-c:a', 'pcm_s16le'
  ```
- ‚úÖ Loudness normalization optional
- ‚úÖ Mono downmix
- ‚úÖ Multiple format support

**Perfect alignment with plan!**

---

### ‚úÖ Step 4: Pipeline Overview (95% COMPLETE)

**Implemented**:
- ‚úÖ 12-stage pipeline (exceeds plan's requirements)
  1. Demux
  2. TMDB metadata
  3. Pre-ASR NER
  4. Silero VAD
  5. PyAnnote VAD
  6. Diarization
  7. ASR (WhisperX)
  8. Second-pass translation ‚≠ê (bonus)
  9. Lyrics detection ‚≠ê (bonus)
  10. Post-NER
  11. Subtitle generation
  12. Mux

**Gaps**:
- ‚ö†Ô∏è No explicit "fast path" vs "polish path" toggle
- ‚ö†Ô∏è Word alignment part of ASR (not separate explicit stage)

**Evidence**: `scripts/pipeline.py` orchestrates all stages with native/Docker execution

---

### ‚úÖ Step 5: Implementation Details (90% COMPLETE)

#### 5.1 VAD (100% COMPLETE) ‚≠ê
**Implemented**:
- ‚úÖ Silero VAD (`docker/silero-vad/`)
- ‚úÖ PyAnnote VAD (`docker/pyannote-vad/`)
- ‚úÖ Configurable thresholds
- ‚úÖ Both stages can be toggled

**Perfect implementation!**

```python
# Config from .env
SILERO_THRESHOLD=0.6
SILERO_MIN_SPEECH_DURATION_MS=250
SILERO_MIN_SILENCE_DURATION_MS=300
PYANNOTE_ONSET=0.5
PYANNOTE_OFFSET=0.5
```

#### 5.2 Diarization (95% COMPLETE)
**Implemented**:
- ‚úÖ PyAnnote diarization (`docker/diarization/`)
- ‚úÖ Auto speaker mapping from TMDB cast
- ‚úÖ Configurable min/max speakers
- ‚úÖ **FIX APPLIED**: Dict format handling (Nov 9, 2025)

**Gaps**:
- ‚ö†Ô∏è No explicit "escalation rule" for overlap detection
- ‚ö†Ô∏è Manual speaker map via `SPEAKER_MAP` env var (not per-film config)

#### 5.3 ASR + Translate (100% COMPLETE) ‚≠ê
**Implemented**:
- ‚úÖ WhisperX with `task=translate` mode
- ‚úÖ Large-v3 model support
- ‚úÖ Initial prompts supported via `WHISPER_INITIAL_PROMPT`
- ‚úÖ Comprehensive Whisper parameters:
  ```python
  whisper_temperature: "0.0,0.2,0.4,0.6,0.8,1.0"
  whisper_beam_size: 5
  whisper_patience: 1.0
  whisper_length_penalty: 1.0
  ```

**Perfect implementation!**

#### 5.4 Word Alignment (100% COMPLETE) ‚≠ê
**Implemented**:
- ‚úÖ WhisperX aligner integrated
- ‚úÖ `WHISPERX_ALIGN_EXTEND=2.0`
- ‚úÖ `WHISPERX_ALIGN_FROM_PREV=true`

#### 5.5 Context-Aware Post-Editing (60% COMPLETE)
**Implemented**:
- ‚úÖ Post-NER entity correction (`docker/post-ner/`)
- ‚úÖ TMDB character matching
- ‚úÖ **BONUS**: Second-pass translation with NLLB
- ‚úÖ **BONUS**: Lyrics detection

**Gaps**: ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
- ‚ùå **No glossary system** (Hinglish‚ÜíEnglish TSV)
- ‚ùå No per-film memory/catchphrase tracking
- ‚ùå No honorifics mapping (ji ‚Üí sir/ma'am)
- ‚ùå No slang_map configuration
- ‚ùå No italics_for_songs toggle (hardcoded?)

**CRITICAL GAP**: This is the biggest missing piece!

#### 5.6 Subtitle Formatting (85% COMPLETE)
**Implemented**:
- ‚úÖ Max 2 lines, 42 chars/line
- ‚úÖ Speaker labels formatted `[Speaker Name]`
- ‚úÖ Subtitle merging for short gaps
- ‚úÖ Duration limits

**Gaps**:
- ‚ö†Ô∏è No CPS enforcement (15 target, 17 cap)
- ‚ö†Ô∏è No italics for songs (or unclear if implemented)
- ‚ö†Ô∏è No `[SFX]` bracket formatting

#### 5.7 QA Metrics (40% COMPLETE)
**Implemented**:
- ‚úÖ Comprehensive logging
- ‚úÖ Segment statistics
- ‚úÖ Duration tracking

**Gaps**: ‚ö†Ô∏è‚ö†Ô∏è
- ‚ùå No WER/MER calculation
- ‚ùå No CPS violation detection
- ‚ùå No terminology coverage tracking
- ‚ùå No QC reports generated

---

### ‚úÖ Step 6: Tech Stack (100% COMPLETE) ‚≠ê

**Implemented**:
- ‚úÖ ffmpeg (demux, mux)
- ‚úÖ Silero VAD
- ‚úÖ pyannote.audio (VAD + diarization)
- ‚úÖ WhisperX (ASR + alignment)
- ‚úÖ spaCy (NER)
- ‚úÖ transformers (NLLB, lyrics detection)
- ‚úÖ Docker containerization
- ‚úÖ Native Python execution (macOS MPS, Windows)

**Perfect alignment!**

---

### ‚úÖ Step 7: Orchestration & Config (90% COMPLETE)

**Implemented**:
- ‚úÖ Environment-based configuration (`.env` files)
- ‚úÖ Toggleable stages via config
- ‚úÖ Job-specific config per run
- ‚úÖ Hardware detection & optimization

**Gaps**:
- ‚ö†Ô∏è Config is `.env` format, not YAML (different from plan)
- ‚ö†Ô∏è No `config/pipeline.yaml` (uses `.env` instead)

**Evidence**: Per-job config at `.{JOB_ID}.env`

---

### ‚ùå Step 8: Hinglish‚ÜíEnglish Glossary (0% COMPLETE) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**CRITICAL GAP**:
- ‚ùå **No glossary system implemented**
- ‚ùå No `glossary/hinglish_master.tsv`
- ‚ùå No per-film prompt files
- ‚ùå No terminology enforcement

**Impact**: 
- Translations may be inconsistent
- Hinglish terms (yaar, bhai, jugaad) not standardized
- Honorifics (ji) not handled
- No context-aware term selection

**Recommendation**:
```
glossary/
‚îú‚îÄ hinglish_master.tsv
‚îú‚îÄ prompts/
‚îÇ  ‚îú‚îÄ jaane_tu_2008.txt
‚îÇ  ‚îú‚îÄ dil_chahta_hai_2001.txt
‚îÇ  ‚îî‚îÄ rangeela_1995.txt
‚îî‚îÄ README.md
```

---

### ‚ö†Ô∏è Step 9: Example Commands (80% COMPLETE)

**Implemented**:
- ‚úÖ Shell scripts: `run_pipeline.sh`, `resume-pipeline.sh`, `prepare-job.sh`
- ‚úÖ Python orchestrator: `scripts/pipeline.py`
- ‚úÖ Docker & native execution modes

**Gaps**:
- ‚ö†Ô∏è No glossary apply commands
- ‚ö†Ô∏è No terminology linter
- ‚ö†Ô∏è No explicit one-liner "fast path" demo

---

### ‚ùå Step 10: Human-in-the-Loop QA (20% COMPLETE) ‚ö†Ô∏è‚ö†Ô∏è

**Implemented**:
- ‚úÖ Manual review possible (output files accessible)
- ‚úÖ Resume capability for corrections

**Gaps**: ‚ö†Ô∏è‚ö†Ô∏è
- ‚ùå No reviewer checklist
- ‚ùå No QA workflow tools
- ‚ùå No linguist pass instructions
- ‚ùå No subtitle editor guidelines
- ‚ùå No spot-check automation

**Recommendation**: Create `tools/qa_review.py` with:
- CPS violation highlighter
- Terminology consistency checker
- Timing visualization
- Diff viewer for corrections

---

### ‚ö†Ô∏è Step 11: Rollout Plan (70% COMPLETE)

**Implemented**:
- ‚úÖ Job-based workflow supports pilot films
- ‚úÖ Per-job configuration
- ‚úÖ Resume capability for iteration

**Gaps**:
- ‚ö†Ô∏è No documented pilot plan
- ‚ö†Ô∏è No Makefile for QC commands
- ‚ö†Ô∏è No maintenance procedures

---

### ‚úÖ Step 12: Risks & Mitigations (85% COMPLETE)

**Implemented**:
- ‚úÖ Overlap handling via diarization
- ‚úÖ Multiple VAD approaches (Silero + PyAnnote)
- ‚úÖ GPU optimization (MPS, CUDA)
- ‚úÖ Retry logic and error handling

**Gaps**:
- ‚ö†Ô∏è Over-literal translations (no glossary to mitigate)
- ‚ö†Ô∏è Name/term drift (no terminology linter)

---

### ‚úÖ Step 13: Deliverables (85% COMPLETE)

**Implemented**:
```
‚úÖ config/ (env-based, not YAML)
‚úÖ scripts/ (orchestration, prepare-job, etc.)
‚úÖ docker/ (all 12 stages)
‚úÖ shared/ (common utilities)
‚úÖ out/ (job outputs with SRT files)
‚úÖ README.md, DOCUMENTATION_STATUS.md
```

**Gaps**:
```
‚ùå glossary/ (missing entirely)
‚ùå tools/term_lint.py
‚ùå tools/check_cps.py
‚ö†Ô∏è No qc.json reports
```

---

### ‚ö†Ô∏è Step 14: Appendix (90% COMPLETE)

**Implemented**:
- ‚úÖ CPS target configurable (not enforced at 15/17)
- ‚úÖ Max line width: 42 chars ‚úì
- ‚úÖ Max lines: 2 ‚úì
- ‚úÖ VAD: Silero + PyAnnote ‚úì
- ‚úÖ ASR: WhisperX large-v3 translate mode ‚úì
- ‚úÖ Diarization: PyAnnote ‚úì

**Gaps**:
- ‚ö†Ô∏è No explicit "fast path" one-liner
- ‚ö†Ô∏è No env toggle documentation in main README

---

## Priority Gap Summary

### üî¥ CRITICAL (Must Have)
1. **Glossary System** (Step 8) - 0% complete
   - Hinglish‚ÜíEnglish terminology TSV
   - Per-film prompts
   - Glossary application in post-editing
   - **Estimated effort**: 2-3 days

2. **CPS Enforcement** (Step 5.6) - Missing
   - Calculate CPS for each subtitle
   - Flag violations > 17
   - Auto-reflow if possible
   - **Estimated effort**: 1 day

3. **QA Metrics & Reports** (Step 5.7) - 40% complete
   - WER/MER calculation
   - CPS violation report
   - Terminology coverage
   - Export qc.json
   - **Estimated effort**: 2 days

### üü° HIGH PRIORITY (Should Have)
4. **Human QA Workflow** (Step 10) - 20% complete
   - Reviewer checklist
   - QA review tools
   - Correction workflow
   - **Estimated effort**: 3-4 days

5. **Per-Film Configuration** (Step 2) - Missing
   - Film catalog YAML
   - Per-film prompts/notes
   - Memory system for catchphrases
   - **Estimated effort**: 1-2 days

6. **Advanced Post-Editing** (Step 5.5) - 60% complete
   - Honorifics mapping
   - Slang map
   - Context-aware rules
   - **Estimated effort**: 2-3 days

### üü¢ MEDIUM PRIORITY (Nice to Have)
7. **YAML Config Migration** (Step 7)
   - Convert .env to pipeline.yaml
   - **Estimated effort**: 1 day

8. **QA Tools** (Steps 9, 10, 13)
   - term_lint.py
   - check_cps.py
   - QA review interface
   - **Estimated effort**: 2-3 days

9. **Documentation**
   - Rollout plan
   - Pilot film guide
   - Maintenance procedures
   - **Estimated effort**: 1-2 days

---

## Strengths of Current Implementation

1. **Excellent Pipeline Architecture** ‚≠ê
   - 12 stages vs 9 in plan (includes bonus features)
   - Clean separation of concerns
   - Resume capability
   - Native + Docker execution

2. **Advanced Features Beyond Plan** ‚≠ê
   - Second-pass translation (NLLB)
   - Lyrics detection for songs
   - Hardware auto-detection
   - MPS (Apple Silicon) support
   - Comprehensive logging

3. **Production-Ready Infrastructure** ‚≠ê
   - Docker containerization
   - Environment-based config
   - Error handling and retries
   - Job-based organization
   - Manifest tracking

4. **Strong VAD/ASR/Diarization** ‚≠ê
   - Silero + PyAnnote VAD
   - WhisperX with alignment
   - PyAnnote diarization
   - TMDB auto-mapping

---

## Recommended Implementation Roadmap

### Phase 1: Core Gaps (1-2 weeks)
**Priority: Critical functionality**

Week 1:
- [ ] Day 1-3: Implement glossary system
  - Create `glossary/hinglish_master.tsv`
  - Add glossary loader to post-editing
  - Apply term substitution in subtitle-gen
  
- [ ] Day 4-5: Add CPS enforcement
  - Calculate CPS in subtitle-gen
  - Add CPS violation detection
  - Implement auto-reflow logic

Week 2:
- [ ] Day 6-8: QA metrics & reports
  - Add WER/MER calculation
  - Generate qc.json reports
  - Terminology coverage tracking

- [ ] Day 9-10: Testing & validation
  - Test on pilot films
  - Validate metrics
  - Fix bugs

### Phase 2: QA Workflow (1 week)
- [ ] Create reviewer tools
- [ ] Document QA procedures
- [ ] Build correction workflow
- [ ] Test with human reviewers

### Phase 3: Advanced Features (1 week)
- [ ] Per-film configuration system
- [ ] Advanced post-editing rules
- [ ] Context-aware terminology

### Phase 4: Polish (3-5 days)
- [ ] Documentation
- [ ] YAML config migration (optional)
- [ ] One-liner demos
- [ ] Rollout guide

---

## Code Snippets for Gap Filling

### 1. Glossary System

**Create**: `shared/glossary.py`
```python
import pandas as pd
from pathlib import Path

class HinglishGlossary:
    def __init__(self, tsv_path: Path):
        self.df = pd.read_csv(tsv_path, sep='\t')
        self.term_map = {}
        for _, row in self.df.iterrows():
            options = row['preferred_english'].split('|')
            self.term_map[row['source']] = {
                'options': options,
                'notes': row.get('notes', '')
            }
    
    def apply(self, text: str, context: str = "") -> str:
        """Apply glossary terms to text"""
        for source, data in self.term_map.items():
            if source in text:
                # Use first option for now (can add context logic)
                replacement = data['options'][0]
                text = text.replace(source, replacement)
        return text
```

**Update**: `docker/subtitle-gen/subtitle_gen.py`
```python
from glossary import HinglishGlossary

# After loading segments
if config.get('glossary_enabled', True):
    glossary_path = Path('/app/glossary/hinglish_master.tsv')
    if glossary_path.exists():
        glossary = HinglishGlossary(glossary_path)
        for seg in segments:
            seg['text'] = glossary.apply(seg['text'])
```

### 2. CPS Enforcement

**Update**: `docker/subtitle-gen/subtitle_gen.py`
```python
def calculate_cps(text: str, duration: float) -> float:
    """Calculate characters per second"""
    char_count = len(text.replace('\n', ''))
    return char_count / max(duration, 0.001)

def check_cps_violations(segments, target=15, cap=17):
    """Check for CPS violations"""
    violations = []
    for i, seg in enumerate(segments):
        duration = seg['end'] - seg['start']
        cps = calculate_cps(seg['text'], duration)
        if cps > cap:
            violations.append({
                'index': i,
                'cps': round(cps, 2),
                'severity': 'critical'
            })
        elif cps > target:
            violations.append({
                'index': i,
                'cps': round(cps, 2),
                'severity': 'warning'
            })
    return violations
```

### 3. QC Report Generation

**Create**: `tools/generate_qc_report.py`
```python
import json
from pathlib import Path

def generate_qc_report(job_dir: Path) -> dict:
    """Generate QC report for a job"""
    report = {
        'job_id': job_dir.name,
        'timestamp': datetime.now().isoformat(),
        'metrics': {},
        'violations': {},
        'summary': {}
    }
    
    # Load subtitle file
    srt_files = list(job_dir.glob('en_merged/*.srt'))
    if srt_files:
        # Calculate metrics
        report['metrics']['subtitle_count'] = count_subtitles(srt_files[0])
        report['metrics']['avg_cps'] = calculate_avg_cps(srt_files[0])
        report['violations']['cps'] = check_cps_violations(srt_files[0])
        report['violations']['line_width'] = check_line_width(srt_files[0])
    
    # Save report
    qc_file = job_dir / 'qc_report.json'
    with open(qc_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    return report
```

---

## Conclusion

**Overall Assessment**: **85-90% Complete** üéØ

The **CP-WhisperX-App** project has excellent foundations with a robust pipeline architecture that exceeds the improvement plan in many areas (12 stages vs 9, bonus features like NLLB translation and lyrics detection). 

**The primary gaps are**:
1. ‚ùå **Glossary/terminology system** (critical for Hinglish)
2. ‚ö†Ô∏è **CPS enforcement** (readability requirement)
3. ‚ö†Ô∏è **QA metrics & reports** (quality assurance)
4. ‚ö†Ô∏è **Human QA workflow** (review process)

**Estimated effort to reach 100%**: 3-4 weeks of focused development

**Recommendation**: Prioritize Phase 1 (glossary + CPS + QA metrics) for immediate production readiness. The system is already usable for 1990s/2000s Bollywood films, but these additions will significantly improve output quality and consistency.

---

**Analysis Date**: November 9, 2025  
**Analyst**: Pipeline Architecture Review  
**Next Review**: After Phase 1 implementation
