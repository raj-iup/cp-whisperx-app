# Apple Silicon GPU Acceleration - Quick Reference

## TL;DR

**All 4 ML stages now automatically use MPS (Apple Silicon GPU) with zero configuration!**

```bash
# Setup (one-time)
./scripts/bootstrap.sh  # Auto-installs MLX-Whisper

# Verify (optional)
python3 scripts/verify_mps_usage.py

# Use
./prepare-job.sh movie.mp4 --native
# All stages automatically use GPU! üöÄ
```

---

## What Changed

### Before (2025-11-11)
- ‚ùå PyAnnote VAD: CPU by default
- ‚ùå Diarization: CPU by default  
- ‚ùå WhisperX ASR: CPU (CTranslate2 limitation)
- ‚ö†Ô∏è Users had to manually configure MPS
- ‚ö†Ô∏è Users had to manually install MLX-Whisper

### After (2025-11-12)
- ‚úÖ **All stages:** Auto-detect and use MPS
- ‚úÖ **MLX-Whisper:** Auto-installed in bootstrap
- ‚úÖ **Zero config:** Just run bootstrap and go!

---

## Device Usage

| Stage | Device | Speedup | Auto-Detected |
|-------|--------|---------|---------------|
| Silero VAD | MPS | 3-5x | ‚úÖ Yes |
| PyAnnote VAD | MPS | 2-4x | ‚úÖ Yes |
| Diarization | MPS | 5-10x | ‚úÖ Yes |
| WhisperX ASR | MPS (MLX) | 2-4x | ‚úÖ Yes |

**Overall speedup:** 2-4x faster end-to-end! üéâ

---

## How to Verify GPU is Being Used

### Method 1: Verification Tool (Recommended)

```bash
python3 scripts/verify_mps_usage.py
```

Expected output:
```
‚úÖ PERFECT SETUP - All stages ready for MPS acceleration!
```

### Method 2: Check Logs

```bash
# After running a job
grep -h "Device:" out/*/logs/*.log
```

Expected output:
```
[Silero VAD] Device: MPS (Apple Silicon GPU)
‚úì PyAnnote VAD pipeline loaded on device: MPS
‚úì Diarization model moved to MPS
Device: MPS (Apple Silicon GPU)
```

### Method 3: Check Manifest

```bash
cat out/*/manifest.json | jq .devices
```

Expected output:
```json
{
  "silero_vad": {
    "requested": "auto",
    "actual": "mps",
    "fallback": false
  },
  "pyannote_vad": {
    "requested": "auto",
    "actual": "mps",
    "fallback": false
  },
  "diarization": {
    "requested": "auto",
    "actual": "mps",
    "fallback": false
  },
  "whisperx": {
    "requested": "auto",
    "actual": "mps",
    "fallback": false
  }
}
```

---

## Bootstrap Process

The bootstrap script now:

1. ‚úÖ Installs PyTorch with MPS support
2. ‚úÖ Installs WhisperX and dependencies  
3. ‚úÖ **Auto-installs MLX-Whisper** (Apple Silicon only)
4. ‚úÖ Configures all devices to `"auto"`
5. ‚úÖ Validates FFmpeg and directories

```bash
$ ./scripts/bootstrap.sh

Installing Python packages...
‚úì torch, torchaudio, whisperx installed

MLX-WHISPER (APPLE SILICON GPU ACCELERATION)
Detected Apple Silicon (M1/M2/M3) - installing MLX-Whisper...
Installing mlx-whisper for 2-4x faster ASR on Apple Silicon...
‚úì MLX-Whisper installed: 0.4.0
  ‚Üí WhisperX ASR will use Metal/MPS acceleration
  ‚Üí Expected speedup: 2-4x faster than CPU
```

---

## Configuration

### All Stages Default to Auto

```bash
# config/.env (defaults)
WHISPERX_DEVICE=auto
WHISPERX_BACKEND=auto
PYANNOTE_DEVICE=auto
DIARIZATION_DEVICE=auto
```

No manual configuration needed!

### Manual Override (Optional)

If you need to force a specific device:

```bash
# Force MPS
export WHISPERX_DEVICE=mps
export PYANNOTE_DEVICE=mps
export DIARIZATION_DEVICE=mps

# Force CPU (for testing)
export WHISPERX_DEVICE=cpu
export PYANNOTE_DEVICE=cpu
export DIARIZATION_DEVICE=cpu
```

---

## Troubleshooting

### "MLX-Whisper not installed"

**Solution:**
```bash
pip install mlx-whisper>=0.4.0
```

Or re-run bootstrap:
```bash
rm -rf .bollyenv
./scripts/bootstrap.sh
```

### "Device: CPU" in logs (expected MPS)

**Check 1:** Verify you're on Apple Silicon
```bash
uname -m  # Should show: arm64
```

**Check 2:** Verify MPS is available
```bash
python3 -c "import torch; print(torch.backends.mps.is_available())"
# Should print: True
```

**Check 3:** Run verification tool
```bash
python3 scripts/verify_mps_usage.py
```

### Stage still using CPU

**Solution:** Check configuration
```bash
python3 -c "
from shared.config import PipelineConfig
c = PipelineConfig()
print(f'PYANNOTE_DEVICE: {c.pyannote_device}')
print(f'DIARIZATION_DEVICE: {c.diarization_device}')
print(f'WHISPERX_DEVICE: {c.whisperx_device}')
"
```

All should show `auto`. If not, remove any custom config files.

---

## Performance Expectations

### M1 Pro (16GB) - 2.5-hour movie

| Stage | CPU Time | MPS Time | Speedup |
|-------|----------|----------|---------|
| Silero VAD | 10 min | 3 min | 3.3x |
| PyAnnote VAD | 30 min | 10 min | 3x |
| Diarization | 4 hours | 25 min | 9.6x ‚≠ê |
| WhisperX ASR | 10 hours | 4 hours | 2.5x |
| **Total** | **15+ hours** | **5-6 hours** | **2.5-3x** |

### M2 Max (32GB) - 2.5-hour movie

| Stage | CPU Time | MPS Time | Speedup |
|-------|----------|----------|---------|
| Total | 13 hours | 4 hours | 3.25x |

### M3 Max (64GB) - 2.5-hour movie

| Stage | CPU Time | MPS Time | Speedup |
|-------|----------|----------|---------|
| Total | 11 hours | 3 hours | 3.7x |

---

## Common Commands

### Check GPU Usage (during processing)

```bash
# Watch GPU activity
sudo powermetrics --samplers gpu_power -i 1000

# During ML stages you should see:
# GPU Power: 8-15W (active)
# GPU Utilization: 60-90%
```

### View All Device Logs

```bash
# Show all device-related log entries
grep -h "Device:\|MPS\|CUDA\|GPU" out/*/logs/*.log | sort -u
```

### Compare CPU vs MPS Performance

```bash
# Force CPU
WHISPERX_DEVICE=cpu time ./prepare-job.sh movie.mp4

# Force MPS  
WHISPERX_DEVICE=mps time ./prepare-job.sh movie.mp4

# Compare times
```

---

## FAQ

**Q: Do I need to do anything special for MPS?**  
A: No! Just run `./scripts/bootstrap.sh` and everything is automatic.

**Q: Will this work on Intel Mac?**  
A: No, MPS is Apple Silicon only. Intel Macs will use CPU (or CUDA if NVIDIA eGPU).

**Q: Can I use MLX on non-Apple hardware?**  
A: No, MLX is Apple Silicon only. Other platforms use WhisperX with CUDA or CPU.

**Q: Is quality the same on CPU vs MPS?**  
A: Yes! Same models, same quality. MPS just makes it faster.

**Q: How does native mode differ from other platforms?**  
A: Native mode provides direct GPU access through MPS (Metal Performance Shaders) and MLX for optimal performance on Apple Silicon. No containerization overhead.

**Q: How do I know if MLX is being used?**  
A: Check logs for "Backend: Apple MLX (Metal)" or run `python3 scripts/verify_mps_usage.py`

---

## Summary

### What You Get

‚úÖ **Zero configuration** - Auto-detects and uses MPS  
‚úÖ **Auto-installation** - MLX installed during bootstrap  
‚úÖ **Clear logging** - See exactly which device is used  
‚úÖ **Verification tool** - Check setup before running  
‚úÖ **2-4x speedup** - All stages GPU-accelerated

### What You Do

1. Run bootstrap once: `./scripts/bootstrap.sh`
2. Verify (optional): `python3 scripts/verify_mps_usage.py`
3. Process movies: `./prepare-job.sh movie.mp4 --native`

That's it! Enjoy 2-4x faster processing on Apple Silicon! üöÄ

---

**Updated:** 2025-11-12  
**Status:** ‚úÖ Production Ready  
**Platform:** macOS Apple Silicon (M1/M2/M3/M4)
