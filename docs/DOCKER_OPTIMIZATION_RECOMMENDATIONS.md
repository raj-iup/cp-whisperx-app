# Docker Image Build Optimization Recommendations

**Analysis Date:** November 4, 2025  
**Analyzed:** All Dockerfiles and requirements files in `docker/` directory

---

## Current Issues Identified

### 1. **Redundant PyTorch Installations**

**Problem:** Almost every stage re-installs PyTorch/torchaudio with different versions.

**Affected Stages:**
- `asr/` - torch 2.2.1
- `diarization/` - torch 2.0.1, torchaudio 2.0.2
- `pyannote-vad/` - torch 2.8.0, torchaudio 2.8.0
- `silero-vad/` - torch >=2.0.0
- `lyrics-detection/` - torch >=2.0.0
- `second-pass-translation/` - torch >=2.0.0

**Impact:**
- PyTorch is **~2-3 GB per installation**
- Each stage downloads and installs independently
- No layer caching benefit across stages
- Total waste: **~10-15 GB** across all GPU images

---

### 2. **Missing Shared Requirements File**

**Problem:** Common dependencies duplicated across multiple stages.

**Duplicated Packages:**
```
numpy>=1.24.0        - 6 stages
soundfile>=0.12.1    - 5 stages
scipy>=1.10.0        - 4 stages
python-dotenv        - 5 stages
transformers         - 4 stages
whisperx             - 3 stages
```

**Impact:**
- Repeated downloads during builds
- No layer caching
- Longer build times

---

### 3. **Base Image Doesn't Include ML Dependencies**

**Problem:** CPU base image (`base/`) includes heavy dependencies in `requirements.txt` but they're never installed.

**File:** `docker/base/requirements.txt`
```
torch>=2.3,<3.0
torchaudio>=2.3,<3.0
openai-whisper>=20231117
whisperx>=3.1.0
pyannote.audio>=3.1.0
...
```

**Reality:** These are **never installed** in the base image Dockerfile.

**Impact:**
- Misleading requirements file
- No actual benefit
- Confusion for developers

---

### 4. **Inconsistent Package Versions**

**Problem:** Same package installed with different version constraints.

**Examples:**
```
numpy:
  - numpy>=1.24.0,<2.0.0  (asr)
  - numpy>=1.24.0         (multiple)
  - numpy<2.0,>=1.26      (post-ner)
  - numpy>=2.0,<3.0       (asr requirements.txt)

whisperx:
  - whisperx==3.7.2       (asr requirements.txt)
  - whisperx==3.7.2       (diarization requirements.txt)
  - whisperx (no version) (diarization Dockerfile)

pyannote.audio:
  - pyannote.audio==3.1.1 (diarization Dockerfile)
  - pyannote.audio==3.4.0 (diarization requirements.txt)
  - pyannote.audio==3.4.0 (pyannote-vad Dockerfile)
```

**Impact:**
- Version conflicts
- Unpredictable behavior
- Build failures

---

### 5. **Unused System Packages in Base Images**

**Problem:** Base images install build tools that may not be needed.

**CPU Base:**
```dockerfile
build-essential  # C compiler - needed?
git              # Only for pip installs from git
```

**CUDA Base:**
```dockerfile
software-properties-common  # Only for adding PPA
build-essential            # C compiler - needed?
```

**Impact:**
- Larger base images
- Slower builds
- Unnecessary attack surface

---

### 6. **No Multi-Stage Builds**

**Problem:** Build dependencies remain in final images.

**Example:** `diarization/Dockerfile`
```dockerfile
RUN apt-get install -y \
    libavformat-dev \
    libavcodec-dev \
    ...
```

These `-dev` packages are **only needed for compilation**, not runtime.

**Impact:**
- 100-200 MB extra per image
- Security risk (more packages = more CVEs)

---

### 7. **Separate Base Images for CPU/CUDA**

**Problem:** Two completely separate base images with duplicated system setup.

**Current:**
- `base/` (python:3.11-slim)
- `base-cuda/` (nvidia/cuda:12.1.0)

**Duplication:**
- Package installation logic
- User setup
- Directory structure
- Environment variables

**Impact:**
- Maintenance burden
- Code duplication
- Inconsistencies

---

## Recommended Optimizations

### **Optimization 1: Unified Base Image with ML Dependencies**

**Create:** `docker/base-ml/Dockerfile` - Shared ML base for all GPU stages

```dockerfile
# docker/base-ml/Dockerfile
FROM rajiup/cp-whisperx-app-base:cuda

LABEL description="ML base with PyTorch and common dependencies"

USER root

# Install PyTorch ONCE with a fixed, compatible version
# torch 2.1.0 is compatible with most pyannote versions
RUN pip install --no-cache-dir \
    torch==2.1.0+cu121 \
    torchaudio==2.1.0+cu121 \
    --index-url https://download.pytorch.org/whl/cu121

# Install common ML packages ONCE
RUN pip install --no-cache-dir \
    numpy==1.24.3 \
    scipy==1.11.4 \
    soundfile==0.12.1 \
    librosa==0.10.1 \
    transformers==4.35.0 \
    huggingface-hub==0.20.3

USER appuser
WORKDIR /app
```

**Benefits:**
- PyTorch installed **once** (saves 2-3 GB per image)
- Common packages shared (saves 500 MB+ per image)
- Better layer caching
- Faster builds for all GPU stages

**Estimated Savings:** **15-20 GB total**, **5-10 min build time**

---

### **Optimization 2: Consolidate Requirements Files**

**Create:** `docker/requirements-common.txt`

```txt
# docker/requirements-common.txt
# Common dependencies for all ML stages

# Core ML
numpy==1.24.3
scipy==1.11.4
soundfile==0.12.1

# Utilities
python-dotenv==1.2.1
tqdm==4.66.0
rich==14.2.0

# File formats
pysubs2==1.8.0
```

**Update stage Dockerfiles:**
```dockerfile
# Install common deps first (cached layer)
COPY docker/requirements-common.txt .
RUN pip install --no-cache-dir -r requirements-common.txt

# Install stage-specific deps
COPY docker/asr/requirements-asr.txt .
RUN pip install --no-cache-dir -r requirements-asr.txt
```

**Benefits:**
- Shared caching across stages
- Single source of truth
- Easier version management

**Estimated Savings:** **3-5 min build time**

---

### **Optimization 3: Multi-Stage Builds for Heavy Dependencies**

**Example:** `docker/post-ner/Dockerfile`

```dockerfile
# Build stage - includes build tools
FROM rajiup/cp-whisperx-app-base:cpu AS builder

USER root

# Install build dependencies
RUN pip install --no-cache-dir \
    spacy>=3.5.0 \
    transformers>=4.30.0 \
    rapidfuzz>=3.0.0

# Download models
RUN python -m spacy download en_core_web_trf

# Runtime stage - minimal
FROM rajiup/cp-whisperx-app-base:cpu

USER root

# Copy installed packages from builder
COPY --from=builder /usr/local/lib/python3.11/site-packages/ /usr/local/lib/python3.11/site-packages/
COPY --from=builder /usr/local/bin/ /usr/local/bin/

# Copy scripts
COPY scripts/ /app/scripts/
COPY shared/ /app/shared/
COPY docker/post-ner/post_ner.py /app/

USER appuser
ENTRYPOINT ["python", "/app/post_ner.py"]
```

**Benefits:**
- No build tools in final image
- Smaller image size (100-200 MB per image)
- Better security posture

**Estimated Savings:** **500 MB - 1 GB total**

---

### **Optimization 4: Pin ALL Dependency Versions**

**Current Issue:** Loose constraints cause version drift.

**Solution:** Lock all versions in a `docker/versions.txt`:

```txt
# docker/versions.txt
# Centralized version management

# Core ML
torch==2.1.0+cu121
torchaudio==2.1.0+cu121
numpy==1.24.3
scipy==1.11.4

# Whisper ecosystem
whisperx==3.7.2
faster-whisper==1.2.0
ctranslate2==4.6.0

# Diarization
pyannote.audio==3.4.0
pyannote.core==5.0.0
pytorch-lightning==2.5.5
speechbrain==1.0.1

# NER
spacy==3.8.7
transformers==4.57.1

# Common
python-dotenv==1.2.1
soundfile==0.12.1
pysubs2==1.8.0
```

**Benefits:**
- Reproducible builds
- No version conflicts
- Easier troubleshooting

---

### **Optimization 5: Remove Unused Dependencies from Base**

**base/Dockerfile:**
```dockerfile
# Before (25 lines)
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    git \
    wget \
    curl \
    ca-certificates \
    build-essential \
    libsndfile1 \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# After (20 lines) - remove unnecessary packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    git \              # Only for git-based pip installs
    wget \             # Can use curl instead
    ca-certificates \
    libsndfile1 \     # Runtime only
    && rm -rf /var/lib/apt/lists/*
```

**Remove:**
- `build-essential` - Not needed in base (stages can add if needed)
- `pkg-config` - Not used
- `curl` OR `wget` - Choose one

**Benefits:**
- 150-200 MB smaller base
- Faster base builds

**Estimated Savings:** **150-200 MB per base variant**

---

### **Optimization 6: Layer Ordering Best Practices**

**Current Issue:** Frequently changing layers near the top.

**Example (Bad):**
```dockerfile
FROM base
COPY scripts/ /app/scripts/    # Changes often
RUN pip install package        # Invalidates cache
```

**Optimized (Good):**
```dockerfile
FROM base

# 1. Install system packages (rarely changes)
RUN apt-get update && ...

# 2. Install Python packages (occasionally changes)
COPY requirements.txt .
RUN pip install -r requirements.txt

# 3. Copy shared code (occasionally changes)
COPY shared/ /app/shared/

# 4. Copy stage-specific code (changes most often)
COPY docker/stage/script.py /app/
```

**Benefits:**
- Better cache hit rate
- Faster iterative development
- Reduced CI/CD time

---

### **Optimization 7: Use BuildKit Cache Mounts**

**Add to Dockerfiles:**
```dockerfile
# syntax=docker/dockerfile:1.4

FROM base

# Use cache mount for pip downloads
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements.txt
```

**Enable in build scripts:**
```bash
export DOCKER_BUILDKIT=1
docker build --cache-from=type=local,src=/tmp/docker-cache ...
```

**Benefits:**
- Persistent pip cache across builds
- 50-70% faster pip installs
- No duplicate downloads

**Estimated Savings:** **10-15 min total build time**

---

### **Optimization 8: Slim Down CUDA Base**

**Current:** Ubuntu 22.04 base (~500 MB)

**Alternative:** Use `runtime-ubuntu22.04` variant (already used) ‚úÖ

**Further optimize:**
```dockerfile
# Remove Python 3.10 that comes with Ubuntu
RUN apt-get purge -y python3.10* && \
    apt-get autoremove -y && \
    apt-get clean

# Set python3.11 as default (already done) ‚úÖ
```

**Benefits:**
- ~100 MB smaller
- Single Python version
- Cleaner environment

---

## Implementation Plan

### Phase 1: Immediate Wins (Low Risk)
1. ‚úÖ Create `docker/requirements-common.txt`
2. ‚úÖ Pin all versions in requirements files
3. ‚úÖ Remove unused packages from base images
4. ‚úÖ Fix layer ordering in all Dockerfiles

**Effort:** 2-3 hours  
**Savings:** 5-10 min build time, 500 MB image size

---

### Phase 2: Structural Changes (Medium Risk)
1. ‚úÖ Create `base-ml` image with PyTorch
2. ‚úÖ Update all GPU stages to use `base-ml`
3. ‚úÖ Enable BuildKit cache mounts
4. ‚úÖ Document version constraints centrally

**Effort:** 4-6 hours  
**Savings:** 15-20 GB total size, 10-15 min build time

---

### Phase 3: Advanced Optimizations (Higher Risk)
1. ‚ö†Ô∏è Implement multi-stage builds for heavy stages
2. ‚ö†Ô∏è Test version compatibility thoroughly
3. ‚ö†Ô∏è Set up automated image scanning

**Effort:** 8-10 hours  
**Savings:** 1-2 GB size, better security

---

## Expected Total Savings

### Build Time
- **Before:** 45-60 minutes (cold build all images)
- **After:** 20-30 minutes (cold build)
- **Savings:** 50-55% reduction

### Image Size
- **Before:** ~25-30 GB total (14 images)
- **After:** ~10-15 GB total
- **Savings:** 15 GB (50% reduction)

### Registry Storage (Monthly)
- **Before:** 30 GB √ó $0.10/GB = $3.00/month
- **After:** 15 GB √ó $0.10/GB = $1.50/month
- **Savings:** $1.50/month ($18/year)

### CI/CD Time
- **Before:** 60 min √ó 10 builds/day = 600 min/day
- **After:** 30 min √ó 10 builds/day = 300 min/day
- **Savings:** 5 hours/day developer time

---

## Specific File Changes Required

### 1. Create `docker/base-ml/Dockerfile`
```dockerfile
FROM rajiup/cp-whisperx-app-base:cuda
# ... (see Optimization 1)
```

### 2. Create `docker/requirements-common.txt`
```txt
numpy==1.24.3
scipy==1.11.4
# ... (see Optimization 2)
```

### 3. Create `docker/versions.txt`
```txt
# Central version management
# ... (see Optimization 4)
```

### 4. Update ALL stage Dockerfiles
- Change FROM line to use `base-ml:cuda` or `base:cpu`
- Remove redundant PyTorch installs
- Add requirements-common.txt
- Reorder layers (system ‚Üí python ‚Üí code)

### 5. Update `docker/build-all-images.sh`
- Build `base-ml` after `base-cuda`
- Update stage dependencies
- Add BuildKit flags

### 6. Remove `docker/base/requirements.txt`
- It's misleading and never used
- Move to proper stage requirements

---

## Risk Assessment

### Low Risk ‚úÖ
- Pinning versions
- Removing unused packages
- Layer reordering
- Documentation

### Medium Risk ‚ö†Ô∏è
- Creating base-ml image
- Changing base image refs
- BuildKit cache mounts

### High Risk üö®
- Multi-stage builds (needs thorough testing)
- Version changes (may break compatibility)

---

## Testing Strategy

### 1. Build Validation
```bash
# Build all images
./docker/build-all-images.sh

# Check sizes
docker images | grep cp-whisperx-app

# Verify no errors
echo $?
```

### 2. Functional Testing
```bash
# Test each stage individually
docker run rajiup/cp-whisperx-app-demux:cpu --help
docker run rajiup/cp-whisperx-app-asr:cuda --help
# ... etc
```

### 3. Integration Testing
```bash
# Run full pipeline
python prepare-job.py in/test.mp4
python pipeline.py --job <job-id>
```

### 4. Performance Testing
- Compare processing times before/after
- Monitor memory usage
- Check GPU utilization

---

## Maintenance Guidelines

### Version Updates
1. Update `docker/versions.txt` FIRST
2. Update stage requirements to reference versions.txt
3. Test compatibility matrix
4. Document breaking changes

### Adding New Stages
1. Inherit from appropriate base (`base-ml`, `base-cuda`, `base-cpu`)
2. Use `requirements-common.txt` first
3. Add only stage-specific deps
4. Follow layer ordering guidelines

### Regular Audits
- Monthly: Check for outdated packages
- Quarterly: Review unused dependencies
- Annually: Re-evaluate base image choices

---

## Alternative Approaches Considered

### Option A: Single Monolithic Base
**Pros:** Simplest
**Cons:** Huge (5-6 GB), wasteful for CPU-only stages
**Verdict:** ‚ùå Rejected

### Option B: Per-Stage Optimization
**Pros:** Minimal
**Cons:** No caching, slow builds
**Verdict:** ‚ùå Rejected

### Option C: Layered Bases (Recommended)
**Pros:** Balance of size and caching
**Cons:** Slightly more complex
**Verdict:** ‚úÖ **RECOMMENDED**

```
base:cpu (500 MB)
‚îú‚îÄ‚îÄ demux:cpu
‚îú‚îÄ‚îÄ tmdb:cpu
‚îú‚îÄ‚îÄ subtitle-gen:cpu
‚îî‚îÄ‚îÄ ...

base-cuda (2 GB)
‚îî‚îÄ‚îÄ base-ml:cuda (4.5 GB)
    ‚îú‚îÄ‚îÄ asr:cuda
    ‚îú‚îÄ‚îÄ diarization:cuda
    ‚îú‚îÄ‚îÄ silero-vad:cuda
    ‚îî‚îÄ‚îÄ ...
```

---

## References

- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [BuildKit Documentation](https://docs.docker.com/build/buildkit/)
- [Multi-Stage Builds](https://docs.docker.com/build/building/multi-stage/)
- [Layer Caching](https://docs.docker.com/build/cache/)

---

## Next Steps

1. **Review** this document with team
2. **Approve** implementation plan
3. **Implement** Phase 1 (immediate wins)
4. **Test** thoroughly
5. **Measure** actual savings
6. **Proceed** to Phase 2 if successful

---

**Recommendation:** Start with **Phase 1** immediately. Low risk, high reward, measurable impact.

**Total Expected Benefit:**
- ‚è±Ô∏è 50% faster builds
- üíæ 50% smaller images  
- üí∞ 50% lower registry costs
- üöÄ Better developer experience

**Implementation Time:** 2-3 hours (Phase 1)

---

**Document maintained by:** DevOps Team  
**Last reviewed:** November 4, 2025  
**Next review:** December 4, 2025
