# Device Detection Feature - Complete ‚úÖ

## Overview

Preflight now automatically detects available compute devices (CUDA, MPS, CPU) and saves the information for pipeline orchestration to use.

---

## üéØ What Was Implemented

### 1. Device Detection in Preflight ‚úÖ

**New Section:** "Compute Devices"

**Detects:**
- **CUDA (NVIDIA GPUs)** - Full details including:
  - Device count
  - GPU names
  - Compute capability
  - Memory per device
- **MPS (Apple Silicon)** - Metal Performance Shaders
- **CPU** - Always available as fallback

### 2. Intelligent Device Recommendation ‚úÖ

**Priority Order:**
1. CUDA (best for ML/AI workloads)
2. MPS (Apple Silicon GPU)
3. CPU (fallback)

**Output Example:**
```
============================================================
Compute Devices
============================================================
‚Ñπ INFO CUDA not available (no NVIDIA GPUs)
‚úì PASS MPS (Apple Silicon) available
       Metal Performance Shaders enabled
‚úì PASS CPU available
       arm (arm64)

Recommended device: MPS
       Using Apple Silicon GPU acceleration
```

### 3. Results Saved to JSON ‚úÖ

**Location:** `out/preflight_results.json`

**New Fields:**
```json
{
  "devices": {
    "cuda": {
      "available": false,
      "device_count": 0,
      "devices": []
    },
    "mps": {
      "available": true
    },
    "cpu": {
      "available": true
    }
  },
  "recommended_device": "mps"
}
```

---

## üìä Device Detection Examples

### Example 1: Apple Silicon Mac (Current System)
```
‚Ñπ INFO CUDA not available (no NVIDIA GPUs)
‚úì PASS MPS (Apple Silicon) available
       Metal Performance Shaders enabled
‚úì PASS CPU available
       arm (arm64)

Recommended device: MPS
       Using Apple Silicon GPU acceleration
```

**JSON Output:**
```json
{
  "devices": {
    "cuda": {"available": false, "device_count": 0, "devices": []},
    "mps": {"available": true},
    "cpu": {"available": true}
  },
  "recommended_device": "mps"
}
```

### Example 2: System with NVIDIA GPU (Hypothetical)
```
‚úì PASS CUDA available
       1 device(s)
       GPU 0: NVIDIA GeForce RTX 4090
       Compute: 8.9, Memory: 24.0GB
‚Ñπ INFO MPS not available (not Apple Silicon)
‚úì PASS CPU available
       x86_64 (x86_64)

Recommended device: CUDA
       Using GPU acceleration for optimal performance
```

**JSON Output:**
```json
{
  "devices": {
    "cuda": {
      "available": true,
      "device_count": 1,
      "devices": [
        {
          "id": 0,
          "name": "NVIDIA GeForce RTX 4090",
          "compute_capability": "8.9",
          "total_memory_gb": 24.0
        }
      ]
    },
    "mps": {"available": false},
    "cpu": {"available": true}
  },
  "recommended_device": "cuda"
}
```

### Example 3: CPU-Only System
```
‚Ñπ INFO CUDA not available (no NVIDIA GPUs)
‚Ñπ INFO MPS not available (not Apple Silicon)
‚úì PASS CPU available
       x86_64 (x86_64)
‚ö† WARNING No GPU acceleration available - pipeline will use CPU (slower)

Recommended device: CPU
       Using CPU (slower, consider GPU for better performance)
```

---

## üîß Pipeline Integration

### How Pipeline Can Use Device Info

```python
import json
from pathlib import Path

# Read preflight results
preflight_file = Path("out/preflight_results.json")
with open(preflight_file) as f:
    preflight = json.load(f)

# Get device information
devices = preflight.get("devices", {})
recommended = preflight.get("recommended_device", "cpu")

print(f"Available devices: {devices}")
print(f"Recommended: {recommended}")

# Use for configuration
if recommended == "cuda":
    # Use CUDA settings
    device = "cuda:0"
    batch_size = 16
    compute_type = "float16"
elif recommended == "mps":
    # Use MPS settings
    device = "mps"
    batch_size = 8
    compute_type = "float32"
else:
    # Use CPU settings
    device = "cpu"
    batch_size = 4
    compute_type = "int8"

print(f"Using device: {device}")
print(f"Batch size: {batch_size}")
print(f"Compute type: {compute_type}")
```

### Creating Per-Job .env Files

```python
def create_job_env(input_file: str, preflight_results: dict):
    """
    Create job-specific .env file based on preflight device detection.
    """
    # Load base config
    base_config = load_config("config/.env")
    
    # Get device info
    recommended = preflight_results.get("recommended_device", "cpu")
    devices = preflight_results.get("devices", {})
    
    # Tune parameters based on device
    if recommended == "cuda":
        gpu_count = devices["cuda"]["device_count"]
        gpu_memory = devices["cuda"]["devices"][0]["total_memory_gb"] if gpu_count > 0 else 0
        
        job_config = {
            **base_config,
            "DEVICE": "cuda",
            "COMPUTE_TYPE": "float16",
            "BATCH_SIZE": min(16, int(gpu_memory / 2)),  # 2GB per batch
            "NUM_WORKERS": gpu_count * 2,
        }
    elif recommended == "mps":
        job_config = {
            **base_config,
            "DEVICE": "mps",
            "COMPUTE_TYPE": "float32",  # MPS doesn't support float16 well
            "BATCH_SIZE": 8,
            "NUM_WORKERS": 4,
        }
    else:
        job_config = {
            **base_config,
            "DEVICE": "cpu",
            "COMPUTE_TYPE": "int8",  # Quantized for CPU
            "BATCH_SIZE": 4,
            "NUM_WORKERS": 2,
        }
    
    # Save job-specific config
    job_name = Path(input_file).stem
    job_env_file = Path("temp") / f"{job_name}.env"
    
    with open(job_env_file, 'w') as f:
        for key, value in job_config.items():
            f.write(f"{key}={value}\n")
    
    return job_env_file
```

---

## ‚úÖ Verification

### Test Results (Current System - Apple Silicon)

**Preflight Output:**
```
============================================================
Compute Devices
============================================================
‚Ñπ INFO CUDA not available (no NVIDIA GPUs)
‚úì PASS MPS (Apple Silicon) available
       Metal Performance Shaders enabled
‚úì PASS CPU available
       arm (arm64)

Recommended device: MPS
       Using Apple Silicon GPU acceleration

============================================================
PREFLIGHT CHECK SUMMARY
============================================================
Passed: 29
Failed: 0
Warnings: 1
```

**Saved Results:**
- ‚úÖ Device information present in JSON
- ‚úÖ Recommended device: `mps`
- ‚úÖ All device types checked
- ‚úÖ Valid JSON format
- ‚úÖ Properly typed (fixed `Dict[str, Any]`)

---

## üìù Updated Check Counts

**Total Checks:** 29 passed (was 27)

**New Checks Added:**
1. MPS (Apple Silicon) availability
2. CPU availability

**Informational (Not Counted as Pass/Fail):**
- CUDA availability (INFO only)

---

## üîÑ Integration with Pipeline Orchestrator

### Step 1: Pipeline Reads Preflight Results

```python
# In pipeline.py
def main():
    # Check preflight
    preflight_file = Path("out/preflight_results.json")
    
    with open(preflight_file) as f:
        preflight = json.load(f)
    
    # Get device recommendation
    device = preflight.get("recommended_device", "cpu")
    devices_info = preflight.get("devices", {})
    
    logger.info(f"Detected compute device: {device.upper()}")
```

### Step 2: Create Job-Specific Configuration

```python
# For each input file
for input_file in input_files:
    job_env = create_job_env(input_file, preflight)
    logger.info(f"Created job config: {job_env}")
    
    # Run pipeline with job-specific config
    orchestrator = PipelineOrchestrator(config_file=job_env)
    orchestrator.run_pipeline(input_file)
```

### Step 3: Containers Use Job Config

```yaml
# docker-compose.yml
services:
  asr:
    image: rajiup/cp-whisperx-app-asr:latest
    env_file:
      - ${JOB_ENV_FILE}  # Job-specific environment
    environment:
      - DEVICE=${DEVICE}
      - COMPUTE_TYPE=${COMPUTE_TYPE}
      - BATCH_SIZE=${BATCH_SIZE}
```

---

## üéØ Benefits

### For Users
1. **Automatic Optimization** - Pipeline auto-tunes based on hardware
2. **No Manual Configuration** - Device selection is automatic
3. **Better Performance** - Uses best available hardware
4. **Clear Visibility** - Shows what's available and being used

### For Pipeline
1. **Smart Defaults** - Different settings per device type
2. **Batch Size Tuning** - Based on GPU memory
3. **Worker Allocation** - Scaled to available GPUs
4. **Fallback Support** - Gracefully degrades to CPU

### For Operations
1. **Hardware Awareness** - Know what's being used
2. **Performance Prediction** - Estimate job duration
3. **Resource Planning** - Allocate based on capability
4. **Troubleshooting** - Device info in logs

---

## ‚úÖ Status

**Feature:** üöÄ **PRODUCTION READY**

- ‚úÖ Device detection implemented
- ‚úÖ All device types supported (CUDA, MPS, CPU)
- ‚úÖ Results saved to JSON
- ‚úÖ Recommendation algorithm working
- ‚úÖ Syntax validated
- ‚úÖ JSON format verified
- ‚úÖ Integration pattern documented
- ‚úÖ Tested on Apple Silicon

**Next Step:** Implement pipeline orchestrator integration to create per-job .env files based on device detection!
