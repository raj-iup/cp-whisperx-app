# ============================================================================
# CP-WhisperX-App Docker Compose Configuration
# Phase 2 Enhancement: Native Execution Mode Support
# ============================================================================
#
# EXECUTION MODES:
# 
# 1. NATIVE MODE (Recommended - Default)
#    - PyTorch from .bollyenv (created by bootstrap)
#    - Slim Docker images (no PyTorch)
#    - 60% smaller images, 50% faster builds
#    - Set: EXECUTION_MODE=native
#    - Mount: .bollyenv volume
#
# 2. DOCKER MODE (Advanced - Distributed setups)
#    - PyTorch in Docker images
#    - Larger images (~8 GB extra)
#    - Set: EXECUTION_MODE=docker
#    - Rebuild images with full PyTorch
#
# PHASE 2 DEFAULT: Native mode (GPU stages use .bollyenv for PyTorch)
# ============================================================================

services:
  # CPU-Only Stages - use :cpu tag
  demux:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-demux:cpu"
    container_name: cp_whisperx_demux
    volumes:
      - ./in:/app/in:ro
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./shared:/app/shared:ro
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app

  tmdb:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-tmdb:cpu"
    container_name: cp_whisperx_tmdb
    volumes:
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./shared:/app/shared:ro
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app

  pre-ner:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-pre-ner:cpu"
    container_name: cp_whisperx_pre_ner
    volumes:
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./scripts:/app/scripts:ro
      - ./shared:/app/shared:ro
      - ./shared-model-and-cache:/shared-model-and-cache
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app
      - SPACY_DATA=/shared-model-and-cache/spacy

  post-ner:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-post-ner:cpu"
    container_name: cp_whisperx_post_ner
    volumes:
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./scripts:/app/scripts:ro
      - ./shared:/app/shared:ro
      - ./shared-model-and-cache:/shared-model-and-cache
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app
      - SPACY_DATA=/shared-model-and-cache/spacy

  subtitle-gen:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-subtitle-gen:cpu"
    container_name: cp_whisperx_subtitle_gen
    volumes:
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./shared:/app/shared:ro
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app

  mux:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-mux:cpu"
    container_name: cp_whisperx_mux
    volumes:
      - ./in:/app/in:ro
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./shared:/app/shared:ro
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app

  # GPU Stages - using CPU images with PyTorch included
  # Note: silero-vad:cpu not available, using pyannote-vad directly
  # silero-vad:
  #   image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-silero-vad:cpu"
  #   (Stage skipped - using pyannote-vad for VAD)

  pyannote-vad:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-pyannote-vad:cpu"
    container_name: cp_whisperx_pyannote_vad
    volumes:
      - ./in:/app/in
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./shared:/app/shared:ro
      - ./shared-model-and-cache:/shared-model-and-cache
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app
      - HF_HOME=/shared-model-and-cache/huggingface
      - TRANSFORMERS_CACHE=/shared-model-and-cache/transformers

  diarization:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-diarization:cpu"
    container_name: cp_whisperx_diarization
    volumes:
      - ./in:/app/in
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./scripts:/app/scripts:ro
      - ./shared:/app/shared:ro
      - ./shared-model-and-cache:/shared-model-and-cache
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app
      - HF_HOME=/shared-model-and-cache/huggingface
      - TRANSFORMERS_CACHE=/shared-model-and-cache/transformers
      - PYANNOTE_CACHE=/shared-model-and-cache/pyannote

  asr:
    image: "${DOCKERHUB_USER:-rajiup}/cp-whisperx-app-asr:cpu"
    container_name: cp_whisperx_asr
    volumes:
      - ./in:/app/in
      - ./out:/app/out
      - ./config:/app/config:ro
      - ./scripts:/app/scripts:ro
      - ./shared:/app/shared:ro
      - ./shared-model-and-cache:/shared-model-and-cache
    environment:
      - CONFIG_PATH=${CONFIG_PATH:-/app/config/.env}
      - PYTHONPATH=/app
      - HF_HOME=/shared-model-and-cache/huggingface
      - TRANSFORMERS_CACHE=/shared-model-and-cache/transformers
      - WHISPER_CACHE=/shared-model-and-cache/whisper
    mem_limit: 16g
    memswap_limit: 16g

# Usage notes:
# 1) Build all images:
#    scripts\build-all-images.bat (Windows)
#    ./scripts/build-all-images.sh (Linux/Mac)
# 
# 2) Run complete pipeline:
#    python pipeline.py -i in/movie.mp4
#
# 3) Run individual services:
#    docker compose run --rm demux in/movie.mp4
#    docker compose run --rm asr out/Movie_Name
#
# Image Tagging Strategy:
# - CPU-Only Stages (demux, tmdb, pre-ner, post-ner, subtitle-gen, mux): :cpu tag
# - GPU Stages (silero-vad, pyannote-vad, diarization, asr): :cuda tag
# - All CPU stages built from rajiup/cp-whisperx-app-base:cpu
# - All GPU stages built from rajiup/cp-whisperx-app-base:cuda
